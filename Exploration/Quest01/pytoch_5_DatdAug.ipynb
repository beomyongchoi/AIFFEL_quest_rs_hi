{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyNJ4auHnd3sgx2mbrw+X9uB"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2ZAa0lrwZqP5","executionInfo":{"status":"ok","timestamp":1753169012676,"user_tz":-540,"elapsed":2986,"user":{"displayName":"김형일","userId":"09633833925626345996"}},"outputId":"865a1428-4aaa-4619-f48e-278f0152c877"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}]},{"cell_type":"code","source":["%cd /content/drive/MyDrive/AIFFEL_quest_rs/Exploration/Quest01/\n","!ls"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5Op9IL8yZ5E-","executionInfo":{"status":"ok","timestamp":1753169038064,"user_tz":-540,"elapsed":111,"user":{"displayName":"김형일","userId":"09633833925626345996"}},"outputId":"33def8ff-c7c5-4239-a242-31acab0aff62"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/AIFFEL_quest_rs/Exploration/Quest01\n","datasets  non_linear.csv  pytoch_3.ipynb  pytoch_5_DatdAug.ipynb  Quest01.ipynb\n","models\t  pytoch_2.ipynb  pytoch_4.ipynb  pytorch_1.ipynb\t  README.md\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"tXFFTs7lXrgA"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!git pull origin main"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5WwEfVVgc_5N","executionInfo":{"status":"ok","timestamp":1753168169744,"user_tz":-540,"elapsed":7646,"user":{"displayName":"김형일","userId":"09633833925626345996"}},"outputId":"c1acc647-65b5-4ed9-c3a5-4d8e29238ecc"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["From https://github.com/nagujean/AIFFEL_quest_rs\n"," * branch            main       -> FETCH_HEAD\n","Already up to date.\n"]}]},{"cell_type":"code","source":["!git add ."],"metadata":{"id":"WMq5kdVVFYhT"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["  !git config --global user.email \"nagujean@gmail.com\"\n","  !git config --global user.name \"nagujean\""],"metadata":{"id":"HN_-_4mVFvEK"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!git commit -m \"commit\""],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"iFM2Q2KOFfS9","executionInfo":{"status":"ok","timestamp":1753103540641,"user_tz":-540,"elapsed":23042,"user":{"displayName":"김형일","userId":"09633833925626345996"}},"outputId":"278f5b47-bb47-4d19-8f55-379513ab0443"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[main befe412] commit\n"," 12 files changed, 2 insertions(+), 2 deletions(-)\n"," rewrite Exploration/Quest01/pytoch_3.ipynb (93%)\n"," rewrite \"Exploration/Quest01/pytoch_3.ipynb\\341\\204\\213\\341\\205\\264 \\341\\204\\211\\341\\205\\241\\341\\204\\207\\341\\205\\251\\341\\206\\253\" (98%)\n"]}]},{"cell_type":"code","source":["!git push origin main"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"DDsPOZ5YF9ub","executionInfo":{"status":"ok","timestamp":1753103547173,"user_tz":-540,"elapsed":1922,"user":{"displayName":"김형일","userId":"09633833925626345996"}},"outputId":"72fe0d82-be16-4338-c5ab-ae155e1b7af8"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Enumerating objects: 33, done.\n","Counting objects:   3% (1/33)\rCounting objects:   6% (2/33)\rCounting objects:   9% (3/33)\rCounting objects:  12% (4/33)\rCounting objects:  15% (5/33)\rCounting objects:  18% (6/33)\rCounting objects:  21% (7/33)\rCounting objects:  24% (8/33)\rCounting objects:  27% (9/33)\rCounting objects:  30% (10/33)\rCounting objects:  33% (11/33)\rCounting objects:  36% (12/33)\rCounting objects:  39% (13/33)\rCounting objects:  42% (14/33)\rCounting objects:  45% (15/33)\rCounting objects:  48% (16/33)\rCounting objects:  51% (17/33)\rCounting objects:  54% (18/33)\rCounting objects:  57% (19/33)\rCounting objects:  60% (20/33)\rCounting objects:  63% (21/33)\rCounting objects:  66% (22/33)\rCounting objects:  69% (23/33)\rCounting objects:  72% (24/33)\rCounting objects:  75% (25/33)\rCounting objects:  78% (26/33)\rCounting objects:  81% (27/33)\rCounting objects:  84% (28/33)\rCounting objects:  87% (29/33)\rCounting objects:  90% (30/33)\rCounting objects:  93% (31/33)\rCounting objects:  96% (32/33)\rCounting objects: 100% (33/33)\rCounting objects: 100% (33/33), done.\n","Delta compression using up to 2 threads\n","Compressing objects:   5% (1/17)\rCompressing objects:  11% (2/17)\rCompressing objects:  17% (3/17)\rCompressing objects:  23% (4/17)\rCompressing objects:  29% (5/17)\rCompressing objects:  35% (6/17)\rCompressing objects:  41% (7/17)\rCompressing objects:  47% (8/17)\rCompressing objects:  52% (9/17)\rCompressing objects:  58% (10/17)\rCompressing objects:  64% (11/17)\rCompressing objects:  70% (12/17)\rCompressing objects:  76% (13/17)\rCompressing objects:  82% (14/17)\rCompressing objects:  88% (15/17)\rCompressing objects:  94% (16/17)\rCompressing objects: 100% (17/17)\rCompressing objects: 100% (17/17), done.\n","Writing objects:   5% (1/17)\rWriting objects:  11% (2/17)\rWriting objects:  17% (3/17)\rWriting objects:  23% (4/17)\rWriting objects:  29% (5/17)\rWriting objects:  35% (6/17)\rWriting objects:  41% (7/17)\rWriting objects:  47% (8/17)\rWriting objects:  52% (9/17)\rWriting objects:  58% (10/17)\rWriting objects:  64% (11/17)\rWriting objects:  70% (12/17)\rWriting objects:  76% (13/17)\rWriting objects:  82% (14/17)\rWriting objects:  88% (15/17)\rWriting objects:  94% (16/17)\rWriting objects: 100% (17/17)\rWriting objects: 100% (17/17), 5.12 KiB | 436.00 KiB/s, done.\n","Total 17 (delta 15), reused 0 (delta 0), pack-reused 0\n","remote: Resolving deltas: 100% (15/15), completed with 15 local objects.\u001b[K\n","To https://github.com/nagujean/AIFFEL_quest_rs.git\n","   f31482b..befe412  main -> main\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"KbiAYJEeHvZW"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 필요한 라이브러리 임포트\n","import torch # PyTorch 라이브러리\n","import pandas as pd # 데이터 처리 라이브러리\n","from torch import nn # 신경망 모듈\n","from torch import optim # 옵티마이저 모듈\n","from torch.utils.data import Dataset, DataLoader, random_split # 데이터 유틸리티\n","\n","# 사용자 정의 데이터셋 클래스 정의\n","class CustomDataset(Dataset):\n","    def __init__(self, file_path):\n","        # CSV 파일 로드 및 특성(x)과 레이블(y) 분리\n","        df = pd.read_csv(file_path)\n","        self.x1 = df.iloc[:, 0].values\n","        self.x2 = df.iloc[:, 1].values\n","        self.x3 = df.iloc[:, 2].values\n","        self.y = df.iloc[:, 3].values\n","        self.length = len(df) # 데이터셋의 총 길이\n","\n","    def __getitem__(self, index):\n","        # 특정 인덱스의 데이터와 레이블을 PyTorch 텐서로 반환\n","        x = torch.FloatTensor([self.x1[index], self.x2[index], self.x3[index]])\n","        y = torch.FloatTensor([int(self.y[index])])\n","        return x, y\n","\n","    def __len__(self):\n","        # 데이터셋의 총 길이 반환\n","        return self.length\n","\n","# 사용자 정의 모델 클래스 정의\n","class CustomModel(nn.Module):\n","    def __init__(self):\n","        super().__init__() # 부모 클래스 초기화\n","        # 선형 레이어와 시그모이드 활성화 함수로 구성된 순차적 모델 정의\n","        self.layer1 = nn.Sequential(\n","            nn.Linear(3, 8), # 입력 3개, 출력 1개인 선형 레이어\n","            nn.BatchNorm1d(8), # 배치 정규화\n","            nn.ReLU(),     #  활성화 함수\n","            nn.Dropout(0.2)\n","        )\n","\n","        self.layer2 = nn.Sequential(\n","            nn.Linear(8, 1), # 입력 3개, 출력 1개인 선형 레이어\n","            nn.Sigmoid()     # 0과 1 사이의 값으로 변환하는 시그모이드 활성화 함수\n","        )\n","        #print(self.layer1[0].weight)\n","\n","        self._init_weights()\n","    def _init_weights(self):\n","        nn.init.xavier_uniform_(self.layer1[0].weight)\n","        self.layer1[0].bias.data.fill_(0.01)\n","\n","        nn.init.xavier_uniform_(self.layer2[0].weight)\n","        self.layer2[0].bias.data.fill_(0.01)\n","\n","        # --- 선택 사항: 가중치 초기화 ---\n","        # for m in self.modules():\n","        #     if isinstance(m, nn.Linear):\n","        #         nn.init.xavier_uniform_(m.weight) # Sigmoid 활성화 함수에 적합\n","        #         if m.bias is not None:\n","        #             nn.init.constant_(m.bias, 0)\n","\n","       # print(self.layer1[0].weight)\n","\n","\n","    def forward(self, x):\n","        # 모델의 순전파 로직 정의\n","        x = self.layer1(x)\n","        x = self.layer2(x)\n","       # print(x)\n","        return x\n","\n","\n","# 데이터셋 로드, 분할 및 데이터로더 생성\n","dataset = CustomDataset(\"./datasets/binary.csv\") # CustomDataset 객체 생성 (데이터 파일 경로 지정)\n","dataset_size = len(dataset)                       # 전체 데이터셋 크기\n","train_size = int(dataset_size * 0.8)              # 훈련 세트 크기 (80%)\n","validation_size = int(dataset_size * 0.1)         # 검증 세트 크기 (10%)\n","test_size = dataset_size - train_size - validation_size # 테스트 세트 크기 (나머지)\n","\n","# 데이터셋을 훈련, 검증, 테스트 세트로 무작위 분할 (재현성을 위해 시드 고정)\n","train_dataset, validation_dataset, test_dataset = random_split(\n","    dataset, [train_size, validation_size, test_size], torch.manual_seed(4)\n",")\n","\n","# DataLoader를 사용하여 각 데이터셋을 미니 배치 단위로 준비\n","train_dataloader = DataLoader(train_dataset, batch_size=64, shuffle=True, drop_last=True)\n","validation_dataloader = DataLoader(validation_dataset, batch_size=4, shuffle=True, drop_last=True)\n","test_dataloader = DataLoader(test_dataset, batch_size=4, shuffle=True, drop_last=True)\n","\n","# GPU 연산 적용 및 모델 설정\n","device = \"cuda\" if torch.cuda.is_available() else \"cpu\" # GPU(CUDA) 사용 가능 여부 확인 후 디바이스 설정\n","model = CustomModel().to(device)                       # CustomModel 인스턴스 생성 및 디바이스로 이동\n","criterion = nn.BCELoss().to(device)                    # 이진 교차 엔트로피 손실 함수 정의 및 디바이스로 이동\n","optimizer = optim.SGD(model.parameters(), lr=0.0001, weight_decay=0.01)   # SGD 옵티마이저 정의 (모델 파라미터와 학습률 지정)\n"],"metadata":{"id":"9rnhyNgCM6cS"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\n","# 모델 학습 진행 (Training Loop)\n","for epoch in range(1000): # 총 10,000 에포크 동안 학습 반복\n","    cost = 0.0 # 현재 에포크의 누적 손실 초기화\n","\n","    for x, y in train_dataloader: # 훈련 데이터로더에서 배치 단위로 데이터 가져오기\n","        x = x.to(device) # 입력 데이터를 디바이스로 이동\n","        y = y.to(device) # 레이블 데이터를 디바이스로 이동\n","\n","        output = model(x) # 순전파: 모델을 통해 예측값 계산\n","        # _lambda = 0.001\n","        # l2_loss = sum(p.pow(2.0).sum() for p in model.parameters())\n","        loss = criterion(output, y) # + _lambda * l2_loss # 손실 계산: 예측값과 실제값 비교\n","\n","        optimizer.zero_grad() # 이전 경사값 초기화\n","        loss.backward()       # 역전파: 손실에 대한 경사 계산\n","\n","        torch.nn.utils.clip_grad_norm_(model.parameters(), 0.1) #그레디언트 클리핑\n","\n","\n","        optimizer.step()      # 파라미터 업데이트: 계산된 경사를 이용해 모델 가중치 조정\n","\n","        cost += loss # 현재 배치 손실을 누적\n","\n","    cost = cost / len(train_dataloader) # 에포크의 평균 손실 계산\n","\n","    if (epoch + 1) % 100 == 0: # 1000 에포크마다 진행 상황 출력\n","        print(f\"Epoch : {epoch+1:4d}, Model : {list(model.parameters())}, Cost : {cost:.3f}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_-mOPH8LM6Zt","executionInfo":{"status":"ok","timestamp":1753168906110,"user_tz":-540,"elapsed":39743,"user":{"displayName":"김형일","userId":"09633833925626345996"}},"outputId":"8830bf37-3718-43d4-8e34-bf8026c4e374"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch :  100, Model : [Parameter containing:\n","tensor([[-0.3970,  0.3272,  0.4517],\n","        [-0.1706,  0.6421, -0.3054],\n","        [ 0.3552,  0.4558,  0.2605],\n","        [-0.2829, -0.3986, -0.2773],\n","        [ 0.4648, -0.2465, -0.4104],\n","        [ 0.4989,  0.3727,  0.3055],\n","        [-0.7150, -0.0527, -0.5851],\n","        [ 0.1793,  0.3559, -0.4534]], requires_grad=True), Parameter containing:\n","tensor([0.0099, 0.0099, 0.0099, 0.0099, 0.0099, 0.0099, 0.0099, 0.0099],\n","       requires_grad=True), Parameter containing:\n","tensor([0.9744, 0.9276, 0.8969, 0.8812, 1.0068, 1.0855, 1.0790, 0.9169],\n","       requires_grad=True), Parameter containing:\n","tensor([-0.0042, -0.0305, -0.1027, -0.1021,  0.0044,  0.1093,  0.0833, -0.0386],\n","       requires_grad=True), Parameter containing:\n","tensor([[ 0.2517,  0.3245, -0.4539,  0.2675, -0.5083,  0.7948, -0.4957,  0.3717]],\n","       requires_grad=True), Parameter containing:\n","tensor([-0.0716], requires_grad=True)], Cost : 0.568\n","Epoch :  200, Model : [Parameter containing:\n","tensor([[-0.3950,  0.3275,  0.4519],\n","        [-0.1692,  0.6422, -0.3037],\n","        [ 0.3545,  0.4558,  0.2596],\n","        [-0.2823, -0.3982, -0.2771],\n","        [ 0.4619, -0.2475, -0.4117],\n","        [ 0.4977,  0.3724,  0.3060],\n","        [-0.7142, -0.0529, -0.5843],\n","        [ 0.1810,  0.3566, -0.4512]], requires_grad=True), Parameter containing:\n","tensor([0.0099, 0.0099, 0.0099, 0.0099, 0.0099, 0.0099, 0.0099, 0.0099],\n","       requires_grad=True), Parameter containing:\n","tensor([0.9732, 0.9258, 0.8943, 0.8789, 1.0062, 1.0863, 1.0798, 0.9151],\n","       requires_grad=True), Parameter containing:\n","tensor([-0.0041, -0.0307, -0.1044, -0.1032,  0.0047,  0.1116,  0.0852, -0.0388],\n","       requires_grad=True), Parameter containing:\n","tensor([[ 0.2510,  0.3221, -0.4508,  0.2635, -0.5088,  0.7970, -0.4999,  0.3694]],\n","       requires_grad=True), Parameter containing:\n","tensor([-0.0726], requires_grad=True)], Cost : 0.544\n","Epoch :  300, Model : [Parameter containing:\n","tensor([[-0.3929,  0.3279,  0.4522],\n","        [-0.1677,  0.6424, -0.3021],\n","        [ 0.3538,  0.4558,  0.2588],\n","        [-0.2818, -0.3978, -0.2768],\n","        [ 0.4590, -0.2485, -0.4131],\n","        [ 0.4964,  0.3721,  0.3066],\n","        [-0.7135, -0.0531, -0.5834],\n","        [ 0.1828,  0.3572, -0.4490]], requires_grad=True), Parameter containing:\n","tensor([0.0098, 0.0098, 0.0098, 0.0098, 0.0098, 0.0098, 0.0098, 0.0098],\n","       requires_grad=True), Parameter containing:\n","tensor([0.9719, 0.9240, 0.8917, 0.8766, 1.0056, 1.0870, 1.0806, 0.9132],\n","       requires_grad=True), Parameter containing:\n","tensor([-0.0040, -0.0309, -0.1061, -0.1043,  0.0049,  0.1138,  0.0871, -0.0389],\n","       requires_grad=True), Parameter containing:\n","tensor([[ 0.2504,  0.3197, -0.4477,  0.2595, -0.5094,  0.7992, -0.5041,  0.3672]],\n","       requires_grad=True), Parameter containing:\n","tensor([-0.0736], requires_grad=True)], Cost : 0.565\n","Epoch :  400, Model : [Parameter containing:\n","tensor([[-0.3909,  0.3282,  0.4525],\n","        [-0.1663,  0.6425, -0.3004],\n","        [ 0.3531,  0.4557,  0.2580],\n","        [-0.2813, -0.3974, -0.2765],\n","        [ 0.4561, -0.2495, -0.4144],\n","        [ 0.4951,  0.3718,  0.3072],\n","        [-0.7128, -0.0533, -0.5825],\n","        [ 0.1846,  0.3578, -0.4468]], requires_grad=True), Parameter containing:\n","tensor([0.0098, 0.0098, 0.0098, 0.0098, 0.0098, 0.0098, 0.0098, 0.0098],\n","       requires_grad=True), Parameter containing:\n","tensor([0.9707, 0.9222, 0.8892, 0.8743, 1.0050, 1.0878, 1.0814, 0.9114],\n","       requires_grad=True), Parameter containing:\n","tensor([-0.0039, -0.0311, -0.1078, -0.1054,  0.0052,  0.1160,  0.0891, -0.0391],\n","       requires_grad=True), Parameter containing:\n","tensor([[ 0.2498,  0.3174, -0.4446,  0.2555, -0.5101,  0.8014, -0.5084,  0.3650]],\n","       requires_grad=True), Parameter containing:\n","tensor([-0.0746], requires_grad=True)], Cost : 0.555\n","Epoch :  500, Model : [Parameter containing:\n","tensor([[-0.3889,  0.3286,  0.4527],\n","        [-0.1649,  0.6427, -0.2988],\n","        [ 0.3524,  0.4557,  0.2571],\n","        [-0.2808, -0.3970, -0.2763],\n","        [ 0.4531, -0.2505, -0.4158],\n","        [ 0.4938,  0.3715,  0.3078],\n","        [-0.7120, -0.0535, -0.5817],\n","        [ 0.1863,  0.3584, -0.4447]], requires_grad=True), Parameter containing:\n","tensor([0.0098, 0.0098, 0.0098, 0.0098, 0.0098, 0.0098, 0.0098, 0.0098],\n","       requires_grad=True), Parameter containing:\n","tensor([0.9694, 0.9204, 0.8866, 0.8721, 1.0045, 1.0887, 1.0822, 0.9096],\n","       requires_grad=True), Parameter containing:\n","tensor([-0.0038, -0.0313, -0.1095, -0.1065,  0.0055,  0.1182,  0.0910, -0.0392],\n","       requires_grad=True), Parameter containing:\n","tensor([[ 0.2491,  0.3151, -0.4416,  0.2515, -0.5108,  0.8037, -0.5126,  0.3628]],\n","       requires_grad=True), Parameter containing:\n","tensor([-0.0756], requires_grad=True)], Cost : 0.545\n","Epoch :  600, Model : [Parameter containing:\n","tensor([[-0.3869,  0.3289,  0.4530],\n","        [-0.1635,  0.6428, -0.2972],\n","        [ 0.3517,  0.4557,  0.2562],\n","        [-0.2802, -0.3966, -0.2761],\n","        [ 0.4502, -0.2515, -0.4171],\n","        [ 0.4925,  0.3712,  0.3083],\n","        [-0.7113, -0.0538, -0.5808],\n","        [ 0.1880,  0.3590, -0.4425]], requires_grad=True), Parameter containing:\n","tensor([0.0098, 0.0098, 0.0098, 0.0098, 0.0098, 0.0098, 0.0098, 0.0098],\n","       requires_grad=True), Parameter containing:\n","tensor([0.9682, 0.9187, 0.8841, 0.8699, 1.0039, 1.0895, 1.0830, 0.9078],\n","       requires_grad=True), Parameter containing:\n","tensor([-0.0037, -0.0315, -0.1111, -0.1076,  0.0058,  0.1204,  0.0929, -0.0394],\n","       requires_grad=True), Parameter containing:\n","tensor([[ 0.2485,  0.3128, -0.4385,  0.2476, -0.5114,  0.8059, -0.5168,  0.3606]],\n","       requires_grad=True), Parameter containing:\n","tensor([-0.0766], requires_grad=True)], Cost : 0.540\n","Epoch :  700, Model : [Parameter containing:\n","tensor([[-0.3848,  0.3293,  0.4532],\n","        [-0.1621,  0.6429, -0.2955],\n","        [ 0.3510,  0.4556,  0.2554],\n","        [-0.2797, -0.3962, -0.2758],\n","        [ 0.4472, -0.2525, -0.4184],\n","        [ 0.4912,  0.3709,  0.3089],\n","        [-0.7106, -0.0540, -0.5799],\n","        [ 0.1898,  0.3596, -0.4403]], requires_grad=True), Parameter containing:\n","tensor([0.0098, 0.0098, 0.0098, 0.0098, 0.0098, 0.0098, 0.0098, 0.0098],\n","       requires_grad=True), Parameter containing:\n","tensor([0.9669, 0.9169, 0.8815, 0.8676, 1.0034, 1.0903, 1.0838, 0.9060],\n","       requires_grad=True), Parameter containing:\n","tensor([-0.0035, -0.0316, -0.1128, -0.1087,  0.0061,  0.1227,  0.0949, -0.0395],\n","       requires_grad=True), Parameter containing:\n","tensor([[ 0.2479,  0.3106, -0.4354,  0.2437, -0.5121,  0.8081, -0.5210,  0.3584]],\n","       requires_grad=True), Parameter containing:\n","tensor([-0.0775], requires_grad=True)], Cost : 0.545\n","Epoch :  800, Model : [Parameter containing:\n","tensor([[-0.3828,  0.3296,  0.4534],\n","        [-0.1608,  0.6430, -0.2939],\n","        [ 0.3503,  0.4556,  0.2545],\n","        [-0.2792, -0.3958, -0.2756],\n","        [ 0.4443, -0.2535, -0.4197],\n","        [ 0.4899,  0.3706,  0.3095],\n","        [-0.7099, -0.0542, -0.5790],\n","        [ 0.1914,  0.3601, -0.4381]], requires_grad=True), Parameter containing:\n","tensor([0.0098, 0.0098, 0.0098, 0.0098, 0.0098, 0.0098, 0.0098, 0.0098],\n","       requires_grad=True), Parameter containing:\n","tensor([0.9657, 0.9152, 0.8790, 0.8655, 1.0029, 1.0911, 1.0846, 0.9043],\n","       requires_grad=True), Parameter containing:\n","tensor([-0.0034, -0.0318, -0.1145, -0.1097,  0.0064,  0.1249,  0.0969, -0.0396],\n","       requires_grad=True), Parameter containing:\n","tensor([[ 0.2474,  0.3084, -0.4324,  0.2398, -0.5128,  0.8104, -0.5251,  0.3563]],\n","       requires_grad=True), Parameter containing:\n","tensor([-0.0785], requires_grad=True)], Cost : 0.540\n","Epoch :  900, Model : [Parameter containing:\n","tensor([[-0.3808,  0.3300,  0.4537],\n","        [-0.1594,  0.6431, -0.2923],\n","        [ 0.3497,  0.4555,  0.2537],\n","        [-0.2787, -0.3953, -0.2753],\n","        [ 0.4413, -0.2545, -0.4209],\n","        [ 0.4886,  0.3703,  0.3101],\n","        [-0.7091, -0.0545, -0.5781],\n","        [ 0.1931,  0.3607, -0.4359]], requires_grad=True), Parameter containing:\n","tensor([0.0098, 0.0098, 0.0098, 0.0098, 0.0098, 0.0098, 0.0098, 0.0098],\n","       requires_grad=True), Parameter containing:\n","tensor([0.9645, 0.9135, 0.8765, 0.8633, 1.0023, 1.0919, 1.0855, 0.9025],\n","       requires_grad=True), Parameter containing:\n","tensor([-0.0033, -0.0319, -0.1161, -0.1107,  0.0068,  0.1272,  0.0989, -0.0397],\n","       requires_grad=True), Parameter containing:\n","tensor([[ 0.2468,  0.3061, -0.4293,  0.2360, -0.5136,  0.8127, -0.5292,  0.3542]],\n","       requires_grad=True), Parameter containing:\n","tensor([-0.0794], requires_grad=True)], Cost : 0.529\n","Epoch : 1000, Model : [Parameter containing:\n","tensor([[-0.3788,  0.3303,  0.4539],\n","        [-0.1580,  0.6432, -0.2907],\n","        [ 0.3490,  0.4555,  0.2529],\n","        [-0.2782, -0.3949, -0.2751],\n","        [ 0.4384, -0.2555, -0.4222],\n","        [ 0.4873,  0.3700,  0.3106],\n","        [-0.7084, -0.0547, -0.5772],\n","        [ 0.1948,  0.3612, -0.4337]], requires_grad=True), Parameter containing:\n","tensor([0.0098, 0.0098, 0.0098, 0.0098, 0.0098, 0.0098, 0.0098, 0.0098],\n","       requires_grad=True), Parameter containing:\n","tensor([0.9632, 0.9118, 0.8739, 0.8611, 1.0018, 1.0928, 1.0863, 0.9008],\n","       requires_grad=True), Parameter containing:\n","tensor([-0.0031, -0.0321, -0.1178, -0.1117,  0.0071,  0.1294,  0.1008, -0.0398],\n","       requires_grad=True), Parameter containing:\n","tensor([[ 0.2462,  0.3039, -0.4263,  0.2321, -0.5143,  0.8150, -0.5334,  0.3522]],\n","       requires_grad=True), Parameter containing:\n","tensor([-0.0803], requires_grad=True)], Cost : 0.524\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"pxcdDgMaM6W7"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"cmlVvqkhM6T3"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"pgJ3pCFeM6Q9"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"WjZeu2JPM6Nj"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"L1tFg81YM6I8"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"JV-brHpVM6Ag"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 필요한 라이브러리 임포트\n","import torch # PyTorch 라이브러리\n","import pandas as pd # 데이터 처리 라이브러리\n","from torch import nn # 신경망 모듈\n","from torch import optim # 옵티마이저 모듈\n","from torch.utils.data import Dataset, DataLoader, random_split # 데이터 유틸리티\n","\n","# 사용자 정의 데이터셋 클래스 정의\n","class CustomDataset(Dataset):\n","    def __init__(self, file_path):\n","        # CSV 파일 로드 및 특성(x)과 레이블(y) 분리\n","        df = pd.read_csv(file_path)\n","        self.x1 = df.iloc[:, 0].values\n","        self.x2 = df.iloc[:, 1].values\n","        self.x3 = df.iloc[:, 2].values\n","        self.y = df.iloc[:, 3].values\n","        self.length = len(df) # 데이터셋의 총 길이\n","\n","    def __getitem__(self, index):\n","        # 특정 인덱스의 데이터와 레이블을 PyTorch 텐서로 반환\n","        x = torch.FloatTensor([self.x1[index], self.x2[index], self.x3[index]])\n","        y = torch.FloatTensor([int(self.y[index])])\n","        return x, y\n","\n","    def __len__(self):\n","        # 데이터셋의 총 길이 반환\n","        return self.length\n","\n","# 사용자 정의 모델 클래스 정의\n","class CustomModel(nn.Module):\n","    def __init__(self):\n","        super().__init__() # 부모 클래스 초기화\n","        # 선형 레이어와 시그모이드 활성화 함수로 구성된 순차적 모델 정의\n","        self.layer = nn.Sequential(\n","            nn.Linear(3, 1), # 입력 3개, 출력 1개인 선형 레이어\n","            nn.Sigmoid()     # 0과 1 사이의 값으로 변환하는 시그모이드 활성화 함수\n","        )\n","\n","    def forward(self, x):\n","        # 모델의 순전파 로직 정의\n","        x = self.layer(x)\n","        return x\n","\n","# 데이터셋 로드, 분할 및 데이터로더 생성\n","dataset = CustomDataset(\"./datasets/binary.csv\") # CustomDataset 객체 생성 (데이터 파일 경로 지정)\n","dataset_size = len(dataset)                       # 전체 데이터셋 크기\n","train_size = int(dataset_size * 0.8)              # 훈련 세트 크기 (80%)\n","validation_size = int(dataset_size * 0.1)         # 검증 세트 크기 (10%)\n","test_size = dataset_size - train_size - validation_size # 테스트 세트 크기 (나머지)\n","\n","# 데이터셋을 훈련, 검증, 테스트 세트로 무작위 분할 (재현성을 위해 시드 고정)\n","train_dataset, validation_dataset, test_dataset = random_split(\n","    dataset, [train_size, validation_size, test_size], torch.manual_seed(4)\n",")\n","\n","# DataLoader를 사용하여 각 데이터셋을 미니 배치 단위로 준비\n","train_dataloader = DataLoader(train_dataset, batch_size=64, shuffle=True, drop_last=True)\n","validation_dataloader = DataLoader(validation_dataset, batch_size=4, shuffle=True, drop_last=True)\n","test_dataloader = DataLoader(test_dataset, batch_size=4, shuffle=True, drop_last=True)\n","\n","# GPU 연산 적용 및 모델 설정\n","device = \"cuda\" if torch.cuda.is_available() else \"cpu\" # GPU(CUDA) 사용 가능 여부 확인 후 디바이스 설정\n","model = CustomModel().to(device)                       # CustomModel 인스턴스 생성 및 디바이스로 이동\n","criterion = nn.BCELoss().to(device)                    # 이진 교차 엔트로피 손실 함수 정의 및 디바이스로 이동\n","optimizer = optim.SGD(model.parameters(), lr=0.0001)   # SGD 옵티마이저 정의 (모델 파라미터와 학습률 지정)\n","\n","# 모델 학습 진행 (Training Loop)\n","for epoch in range(10000): # 총 10,000 에포크 동안 학습 반복\n","    cost = 0.0 # 현재 에포크의 누적 손실 초기화\n","\n","    for x, y in train_dataloader: # 훈련 데이터로더에서 배치 단위로 데이터 가져오기\n","        x = x.to(device) # 입력 데이터를 디바이스로 이동\n","        y = y.to(device) # 레이블 데이터를 디바이스로 이동\n","\n","        output = model(x) # 순전파: 모델을 통해 예측값 계산\n","        loss = criterion(output, y) # 손실 계산: 예측값과 실제값 비교\n","\n","        optimizer.zero_grad() # 이전 경사값 초기화\n","        loss.backward()       # 역전파: 손실에 대한 경사 계산\n","        optimizer.step()      # 파라미터 업데이트: 계산된 경사를 이용해 모델 가중치 조정\n","\n","        cost += loss # 현재 배치 손실을 누적\n","\n","    cost = cost / len(train_dataloader) # 에포크의 평균 손실 계산\n","\n","    if (epoch + 1) % 1000 == 0: # 1000 에포크마다 진행 상황 출력\n","        print(f\"Epoch : {epoch+1:4d}, Model : {list(model.parameters())}, Cost : {cost:.3f}\")\n","\n","# 모델 평가\n","with torch.no_grad(): # 평가 시 경사 계산 비활성화\n","    model.eval()     # 모델을 평가 모드로 전환 (Dropout, BatchNorm 등 영향)\n","    for x, y in validation_dataloader: # 검증 데이터로더에서 배치 가져오기\n","        x = x.to(device) # 입력 데이터를 디바이스로 이동\n","        y = y.to(device) # 레이블 데이터를 디바이스로 이동\n","\n","        outputs = model(x) # 모델의 예측값 계산\n","\n","        print(outputs) # 원본 예측 확률 출력\n","        # 0.5를 기준으로 이진 분류 결과 출력 (True/False)\n","        print(outputs >= torch.FloatTensor([0.5]).to(device))\n","        print(\"--------------------\") # 배치 구분선\n","\n","# 모델 저장\n","# 전체 모델 저장 (환경 종속성 있음, 개발/테스트용)\n","torch.save(\n","    model,\n","    \"models/250719_model.pt\"\n",")\n","\n","# 모델의 state_dict (파라미터만) 저장 (권장되는 방법, 유연성 높음)\n","torch.save(\n","    model.state_dict(),\n","    \"models/250719_model_state_dict\"\n",")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"bjQtrXkN0ICm","executionInfo":{"status":"error","timestamp":1753104413242,"user_tz":-540,"elapsed":233624,"user":{"displayName":"김형일","userId":"09633833925626345996"}},"outputId":"b42266dd-978e-498d-b491-980603e1a695"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch : 1000, Model : [Parameter containing:\n","tensor([[ 0.0028, -0.0006,  0.0036]], device='cuda:0', requires_grad=True), Parameter containing:\n","tensor([0.0949], device='cuda:0', requires_grad=True)], Cost : 0.680\n","Epoch : 2000, Model : [Parameter containing:\n","tensor([[0.0034, 0.0005, 0.0041]], device='cuda:0', requires_grad=True), Parameter containing:\n","tensor([-0.0346], device='cuda:0', requires_grad=True)], Cost : 0.666\n","Epoch : 3000, Model : [Parameter containing:\n","tensor([[0.0045, 0.0017, 0.0051]], device='cuda:0', requires_grad=True), Parameter containing:\n","tensor([-0.1609], device='cuda:0', requires_grad=True)], Cost : 0.652\n","Epoch : 4000, Model : [Parameter containing:\n","tensor([[0.0052, 0.0017, 0.0053]], device='cuda:0', requires_grad=True), Parameter containing:\n","tensor([-0.2843], device='cuda:0', requires_grad=True)], Cost : 0.636\n","Epoch : 5000, Model : [Parameter containing:\n","tensor([[0.0059, 0.0036, 0.0064]], device='cuda:0', requires_grad=True), Parameter containing:\n","tensor([-0.4046], device='cuda:0', requires_grad=True)], Cost : 0.627\n","Epoch : 6000, Model : [Parameter containing:\n","tensor([[0.0065, 0.0034, 0.0068]], device='cuda:0', requires_grad=True), Parameter containing:\n","tensor([-0.5220], device='cuda:0', requires_grad=True)], Cost : 0.613\n","Epoch : 7000, Model : [Parameter containing:\n","tensor([[0.0064, 0.0036, 0.0069]], device='cuda:0', requires_grad=True), Parameter containing:\n","tensor([-0.6366], device='cuda:0', requires_grad=True)], Cost : 0.604\n","Epoch : 8000, Model : [Parameter containing:\n","tensor([[0.0073, 0.0050, 0.0079]], device='cuda:0', requires_grad=True), Parameter containing:\n","tensor([-0.7485], device='cuda:0', requires_grad=True)], Cost : 0.591\n","Epoch : 9000, Model : [Parameter containing:\n","tensor([[0.0074, 0.0058, 0.0082]], device='cuda:0', requires_grad=True), Parameter containing:\n","tensor([-0.8577], device='cuda:0', requires_grad=True)], Cost : 0.585\n","Epoch : 10000, Model : [Parameter containing:\n","tensor([[0.0089, 0.0070, 0.0096]], device='cuda:0', requires_grad=True), Parameter containing:\n","tensor([-0.9644], device='cuda:0', requires_grad=True)], Cost : 0.576\n","tensor([[0.6707],\n","        [0.7298],\n","        [0.7368],\n","        [0.7800]], device='cuda:0')\n","tensor([[True],\n","        [True],\n","        [True],\n","        [True]], device='cuda:0')\n","--------------------\n","tensor([[0.5723],\n","        [0.6746],\n","        [0.4676],\n","        [0.3640]], device='cuda:0')\n","tensor([[ True],\n","        [ True],\n","        [False],\n","        [False]], device='cuda:0')\n","--------------------\n","tensor([[0.5711],\n","        [0.6363],\n","        [0.3985],\n","        [0.6238]], device='cuda:0')\n","tensor([[ True],\n","        [ True],\n","        [False],\n","        [ True]], device='cuda:0')\n","--------------------\n","tensor([[0.6304],\n","        [0.7174],\n","        [0.5751],\n","        [0.6137]], device='cuda:0')\n","tensor([[True],\n","        [True],\n","        [True],\n","        [True]], device='cuda:0')\n","--------------------\n","tensor([[0.7460],\n","        [0.6951],\n","        [0.7555],\n","        [0.6498]], device='cuda:0')\n","tensor([[True],\n","        [True],\n","        [True],\n","        [True]], device='cuda:0')\n","--------------------\n","tensor([[0.8068],\n","        [0.7557],\n","        [0.6456],\n","        [0.7380]], device='cuda:0')\n","tensor([[True],\n","        [True],\n","        [True],\n","        [True]], device='cuda:0')\n","--------------------\n","tensor([[0.4245],\n","        [0.7069],\n","        [0.5908],\n","        [0.7803]], device='cuda:0')\n","tensor([[False],\n","        [ True],\n","        [ True],\n","        [ True]], device='cuda:0')\n","--------------------\n","tensor([[0.7010],\n","        [0.7245],\n","        [0.6922],\n","        [0.3698]], device='cuda:0')\n","tensor([[ True],\n","        [ True],\n","        [ True],\n","        [False]], device='cuda:0')\n","--------------------\n","tensor([[0.5778],\n","        [0.6604],\n","        [0.5856],\n","        [0.7111]], device='cuda:0')\n","tensor([[True],\n","        [True],\n","        [True],\n","        [True]], device='cuda:0')\n","--------------------\n","tensor([[0.4945],\n","        [0.7144],\n","        [0.6279],\n","        [0.6441]], device='cuda:0')\n","tensor([[False],\n","        [ True],\n","        [ True],\n","        [ True]], device='cuda:0')\n","--------------------\n","tensor([[0.7215],\n","        [0.6991],\n","        [0.7697],\n","        [0.5773]], device='cuda:0')\n","tensor([[True],\n","        [True],\n","        [True],\n","        [True]], device='cuda:0')\n","--------------------\n","tensor([[0.6765],\n","        [0.4486],\n","        [0.7386],\n","        [0.7285]], device='cuda:0')\n","tensor([[ True],\n","        [False],\n","        [ True],\n","        [ True]], device='cuda:0')\n","--------------------\n","tensor([[0.6775],\n","        [0.5103],\n","        [0.5580],\n","        [0.6634]], device='cuda:0')\n","tensor([[True],\n","        [True],\n","        [True],\n","        [True]], device='cuda:0')\n","--------------------\n","tensor([[0.5301],\n","        [0.5563],\n","        [0.3649],\n","        [0.4759]], device='cuda:0')\n","tensor([[ True],\n","        [ True],\n","        [False],\n","        [False]], device='cuda:0')\n","--------------------\n","tensor([[0.7732],\n","        [0.7340],\n","        [0.7242],\n","        [0.6318]], device='cuda:0')\n","tensor([[True],\n","        [True],\n","        [True],\n","        [True]], device='cuda:0')\n","--------------------\n","tensor([[0.6975],\n","        [0.3844],\n","        [0.5528],\n","        [0.4122]], device='cuda:0')\n","tensor([[ True],\n","        [False],\n","        [ True],\n","        [False]], device='cuda:0')\n","--------------------\n","tensor([[0.4621],\n","        [0.7796],\n","        [0.5776],\n","        [0.6426]], device='cuda:0')\n","tensor([[False],\n","        [ True],\n","        [ True],\n","        [ True]], device='cuda:0')\n","--------------------\n","tensor([[0.6681],\n","        [0.4632],\n","        [0.4959],\n","        [0.4399]], device='cuda:0')\n","tensor([[ True],\n","        [False],\n","        [False],\n","        [False]], device='cuda:0')\n","--------------------\n","tensor([[0.7320],\n","        [0.5588],\n","        [0.6654],\n","        [0.4713]], device='cuda:0')\n","tensor([[ True],\n","        [ True],\n","        [ True],\n","        [False]], device='cuda:0')\n","--------------------\n","tensor([[0.5140],\n","        [0.7236],\n","        [0.5794],\n","        [0.5472]], device='cuda:0')\n","tensor([[True],\n","        [True],\n","        [True],\n","        [True]], device='cuda:0')\n","--------------------\n","tensor([[0.6813],\n","        [0.5783],\n","        [0.6476],\n","        [0.3883]], device='cuda:0')\n","tensor([[ True],\n","        [ True],\n","        [ True],\n","        [False]], device='cuda:0')\n","--------------------\n","tensor([[0.3664],\n","        [0.7196],\n","        [0.7116],\n","        [0.6520]], device='cuda:0')\n","tensor([[False],\n","        [ True],\n","        [ True],\n","        [ True]], device='cuda:0')\n","--------------------\n","tensor([[0.6375],\n","        [0.5122],\n","        [0.6827],\n","        [0.6221]], device='cuda:0')\n","tensor([[True],\n","        [True],\n","        [True],\n","        [True]], device='cuda:0')\n","--------------------\n","tensor([[0.7563],\n","        [0.6743],\n","        [0.3967],\n","        [0.7840]], device='cuda:0')\n","tensor([[ True],\n","        [ True],\n","        [False],\n","        [ True]], device='cuda:0')\n","--------------------\n","tensor([[0.5797],\n","        [0.7276],\n","        [0.6039],\n","        [0.5545]], device='cuda:0')\n","tensor([[True],\n","        [True],\n","        [True],\n","        [True]], device='cuda:0')\n","--------------------\n"]},{"output_type":"error","ename":"RuntimeError","evalue":"Parent directory .models does not exist.","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","\u001b[0;32m/tmp/ipython-input-4-2113369598.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    103\u001b[0m \u001b[0;31m# 모델 저장\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m \u001b[0;31m# 전체 모델 저장 (환경 종속성 있음, 개발/테스트용)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 105\u001b[0;31m torch.save(\n\u001b[0m\u001b[1;32m    106\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[0;34m\".models/250719_model.pt\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(obj, f, pickle_module, pickle_protocol, _use_new_zipfile_serialization, _disable_byteorder_record)\u001b[0m\n\u001b[1;32m    941\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    942\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0m_use_new_zipfile_serialization\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 943\u001b[0;31m         \u001b[0;32mwith\u001b[0m \u001b[0m_open_zipfile_writer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mopened_zipfile\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    944\u001b[0m             _save(\n\u001b[1;32m    945\u001b[0m                 \u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36m_open_zipfile_writer\u001b[0;34m(name_or_buffer)\u001b[0m\n\u001b[1;32m    808\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    809\u001b[0m         \u001b[0mcontainer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_open_zipfile_writer_buffer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 810\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mcontainer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    811\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    812\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    779\u001b[0m             )\n\u001b[1;32m    780\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 781\u001b[0;31m             \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPyTorchFileWriter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_compute_crc32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    782\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    783\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__exit__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mRuntimeError\u001b[0m: Parent directory .models does not exist."]}]},{"cell_type":"code","source":["import os\n","import torch\n","\n","'''\n","# 모델 저장\n","# 전체 모델 저장 (환경 종속성 있음, 개발/테스트용)\n","torch.save(\n","    model,\n","    \"models/250719_model.pt\"\n",")\n","'''\n","\n","# 모델의 state_dict (파라미터만) 저장 (권장되는 방법, 유연성 높음)\n","torch.save(\n","    model.state_dict(),\n","    \"models/250719_model_state_dict\"\n",")"],"metadata":{"id":"Ej_DlkccLlVA"},"execution_count":null,"outputs":[]}]}