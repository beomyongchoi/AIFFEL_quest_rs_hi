{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 23108,
     "status": "ok",
     "timestamp": 1754571911235,
     "user": {
      "displayName": "김형일",
      "userId": "09633833925626345996"
     },
     "user_tz": -540
    },
    "id": "tcEQDQBKgU-V",
    "outputId": "555ac00e-9b80-4177-c447-7def2c9708f9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3352,
     "status": "ok",
     "timestamp": 1754572187989,
     "user": {
      "displayName": "김형일",
      "userId": "09633833925626345996"
     },
     "user_tz": -540
    },
    "id": "qwV4odAfokwL",
    "outputId": "197c8175-21cd-4cd9-cbdc-50d147235924"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch==2.3.0 in /usr/local/lib/python3.11/dist-packages (2.3.0)\n",
      "Requirement already satisfied: torchtext==0.18.0 in /usr/local/lib/python3.11/dist-packages (0.18.0)\n",
      "Requirement already satisfied: torchvision==0.18.0 in /usr/local/lib/python3.11/dist-packages (0.18.0)\n",
      "Requirement already satisfied: torchaudio==2.3.0 in /usr/local/lib/python3.11/dist-packages (2.3.0)\n",
      "Requirement already satisfied: torchdata==0.11.0 in /usr/local/lib/python3.11/dist-packages (0.11.0)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch==2.3.0) (3.18.0)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from torch==2.3.0) (4.14.1)\n",
      "Requirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from torch==2.3.0) (1.13.1)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch==2.3.0) (3.5)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch==2.3.0) (3.1.6)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch==2.3.0) (2025.3.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch==2.3.0) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch==2.3.0) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch==2.3.0) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.11/dist-packages (from torch==2.3.0) (8.9.2.26)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.11/dist-packages (from torch==2.3.0) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.11/dist-packages (from torch==2.3.0) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.11/dist-packages (from torch==2.3.0) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.11/dist-packages (from torch==2.3.0) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.11/dist-packages (from torch==2.3.0) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /usr/local/lib/python3.11/dist-packages (from torch==2.3.0) (2.20.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch==2.3.0) (12.1.105)\n",
      "Requirement already satisfied: triton==2.3.0 in /usr/local/lib/python3.11/dist-packages (from torch==2.3.0) (2.3.0)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from torchtext==0.18.0) (4.67.1)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from torchtext==0.18.0) (2.32.3)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torchtext==0.18.0) (2.0.2)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from torchvision==0.18.0) (11.3.0)\n",
      "Requirement already satisfied: urllib3>=1.25 in /usr/local/lib/python3.11/dist-packages (from torchdata==0.11.0) (2.5.0)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.11/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch==2.3.0) (12.5.82)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch==2.3.0) (3.0.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->torchtext==0.18.0) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->torchtext==0.18.0) (3.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->torchtext==0.18.0) (2025.7.14)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy->torch==2.3.0) (1.3.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install torch==2.3.0 torchtext==0.18.0 torchvision==0.18.0 torchaudio==2.3.0 torchdata==0.11.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 555
    },
    "executionInfo": {
     "elapsed": 125,
     "status": "error",
     "timestamp": 1754572198061,
     "user": {
      "displayName": "김형일",
      "userId": "09633833925626345996"
     },
     "user_tz": -540
    },
    "id": "phzqhS04gjs2",
    "outputId": "ed007507-82e5-493d-ed12-c04266627897"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "errorDetails": {
      "actions": [
       {
        "action": "open_url",
        "actionText": "Open Examples",
        "url": "/notebooks/snippets/importing_libraries.ipynb"
       }
      ]
     },
     "evalue": "No module named 'torchdata.datapipes'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipython-input-1172238919.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;31m# 3. 데이터셋 로드 및 토크나이저 설정\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m \u001b[0mtrain_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mCoLA\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"train\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# CoLA 학습 데이터 로드\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0mvalid_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mCoLA\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"dev\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# CoLA 검증 데이터 로드\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0mtest_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mCoLA\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"test\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# CoLA 테스트 데이터 로드\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torchtext/data/datasets_utils.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(root, *args, **kwargs)\u001b[0m\n\u001b[1;32m    191\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_root\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    192\u001b[0m                 \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmakedirs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_root\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexist_ok\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 193\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnew_root\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    194\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torchtext/data/datasets_utils.py\u001b[0m in \u001b[0;36mnew_fn\u001b[0;34m(root, split, **kwargs)\u001b[0m\n\u001b[1;32m    153\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    154\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mitem\u001b[0m \u001b[0;32min\u001b[0m \u001b[0m_check_default_set\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msplits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 155\u001b[0;31m             \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mitem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    156\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_wrap_datasets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msplit\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    157\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torchtext/datasets/cola.py\u001b[0m in \u001b[0;36mCoLA\u001b[0;34m(root, split)\u001b[0m\n\u001b[1;32m     75\u001b[0m             \u001b[0;34m\"Package `torchdata` not found. Please install following instructions at https://github.com/pytorch/data\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m         )\n\u001b[0;32m---> 77\u001b[0;31m     \u001b[0;32mfrom\u001b[0m \u001b[0mtorchdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatapipes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miter\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mFileOpener\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mGDriveReader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mHttpReader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mIterableWrapper\u001b[0m  \u001b[0;31m# noqa\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     78\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m     \u001b[0murl_dp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mIterableWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mURL\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'torchdata.datapipes'",
      "",
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "#CoLA 사용 케이스 지속적인 오류로 실행하지 못함\n",
    "\n",
    "\n",
    "# 1. 라이브러리 및 데이터셋 준비\n",
    "import torch\n",
    "from torchtext.datasets import CoLA\n",
    "from transformers import AutoTokenizer\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# 2. 데이터 처리 함수\n",
    "def collator(batch, tokenizer, device): # collator 함수 정의\n",
    "    source, labels, texts = zip(*batch) # batch 데이터를 source, labels, texts로 언패킹\n",
    "    tokenized = tokenizer( # texts를 토큰화하고 패딩/절단 처리\n",
    "        texts,\n",
    "        padding=\"longest\", # 가장 긴 문장을 기준으로 패딩\n",
    "        truncation=True, # 모델 최대 길이 초과 시 절단\n",
    "        return_tensors=\"pt\" # PyTorch 텐서로 반환\n",
    "    )\n",
    "    input_ids = tokenized[\"input_ids\"].to(device) # input_ids를 device(GPU/CPU)로 이동\n",
    "    attention_mask = tokenized[\"attention_mask\"].to(device) # attention_mask를 device로 이동\n",
    "    labels = torch.tensor(labels, dtype=torch.long).to(device) # labels를 텐서로 변환하여 device로 이동\n",
    "    return input_ids, attention_mask, labels # 처리된 데이터 반환\n",
    "\n",
    "# 3. 데이터셋 로드 및 토크나이저 설정\n",
    "train_data = list(CoLA(split=\"train\")) # CoLA 학습 데이터 로드\n",
    "valid_data = list(CoLA(split=\"dev\")) # CoLA 검증 데이터 로드\n",
    "test_data = list(CoLA(split=\"test\")) # CoLA 테스트 데이터 로드\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"gpt2\") # gpt2 토크나이저 불러오기\n",
    "tokenizer.pad_token = tokenizer.eos_token # 패딩 토큰을 eos 토큰으로 설정\n",
    "\n",
    "# 4. 하이퍼파라미터 및 데이터로더 설정\n",
    "epochs = 3 # 총 3 에폭 학습\n",
    "batch_size = 16 # 배치 크기 설정\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\" # GPU 사용 가능 여부 확인\n",
    "train_dataloader = DataLoader( # 학습 데이터로더 생성\n",
    "    train_data,\n",
    "    batch_size=batch_size,\n",
    "    collate_fn=lambda x: collator(x, tokenizer, device), # collator 함수 적용\n",
    "    shuffle=True,) # 데이터 셔플\n",
    "valid_dataloader = DataLoader( # 검증 데이터로더 생성\n",
    "    valid_data, batch_size=batch_size, collate_fn=lambda x: collator(x, tokenizer, device)) # collator 함수 적용\n",
    "test_dataloader = DataLoader( # 테스트 데이터로더 생성\n",
    "    test_data, batch_size=batch_size, collate_fn=lambda x: collator(x, tokenizer, device)) # collator 함수 적용\n",
    "print(\"Train Dataset Length :\", len(train_data)) # 데이터셋 크기 출력\n",
    "print(\"Valid Dataset Length :\", len(valid_data))\n",
    "print(\"Test Dataset Length :\", len(test_data))\n",
    "\n",
    "\n",
    "# 5. 모델 및 옵티마이저 설정\n",
    "from torch import optim\n",
    "from transformers import GPT2ForSequenceClassification\n",
    "model = GPT2ForSequenceClassification.from_pretrained( # GPT2 모델 불러오기\n",
    "    pretrained_model_name_or_path=\"gpt2\",\n",
    "    num_labels=2).to(device) # 2개의 라벨(문법적/비문법적)로 분류하도록 설정\n",
    "model.config.pad_token_id = model.config.eos_token_id # 모델의 패딩 토큰 ID 설정\n",
    "optimizer = optim.Adam(model.parameters(), lr=5e-5) # Adam 옵티마이저 사용, 학습률 5e-5\n",
    "\n",
    "\n",
    "# 6. 학습 및 평가 함수\n",
    "import numpy as np\n",
    "from torch import nn\n",
    "def calc_accuracy(preds, labels): # 정확도 계산 함수 정의\n",
    "    pred_flat = np.argmax(preds, axis=1).flatten() # 예측값을 1차원 배열로 변환\n",
    "    labels_flat = labels.flatten() # 라벨을 1차원 배열로 변환\n",
    "    return np.sum(pred_flat == labels_flat) / len(labels_flat) # 정확도 반환\n",
    "\n",
    "def train(model, optimizer, dataloader): # 학습 함수 정의\n",
    "    model.train() # 모델을 학습 모드로 전환\n",
    "    train_loss = 0.0\n",
    "\n",
    "    for input_ids, attention_mask, labels in dataloader:\n",
    "        outputs = model( # 모델에 데이터 입력\n",
    "            input_ids=input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            labels=labels\n",
    "        )\n",
    "        loss = outputs.loss # 손실(loss) 계산\n",
    "        train_loss += loss.item() # 누적 손실 계산\n",
    "        optimizer.zero_grad() # 그래디언트 초기화\n",
    "        loss.backward() # 역전파\n",
    "        optimizer.step() # 옵티마이저를 통해 가중치 업데이트\n",
    "\n",
    "    train_loss = train_loss / len(dataloader) # 평균 손실 계산\n",
    "    return train_loss\n",
    "\n",
    "def evaluation(model, dataloader): # 평가 함수 정의\n",
    "    with torch.no_grad(): # 그래디언트 계산 비활성화\n",
    "        model.eval() # 모델을 평가 모드로 전환\n",
    "        val_loss, val_accuracy = 0.0, 0.0\n",
    "\n",
    "        for input_ids, attention_mask, labels in dataloader:\n",
    "            outputs = model(\n",
    "                input_ids=input_ids,\n",
    "                attention_mask=attention_mask,\n",
    "                labels=labels\n",
    "            )\n",
    "            logits = outputs.logits # 예측값(logits) 가져오기\n",
    "            loss = outputs.loss # 손실(loss) 계산\n",
    "            logits = logits.detach().cpu().numpy() # 텐서를 CPU로 이동 후 numpy로 변환\n",
    "            label_ids = labels.to(\"cpu\").numpy() # 라벨을 CPU로 이동 후 numpy로 변환\n",
    "            accuracy = calc_accuracy(logits, label_ids) # 정확도 계산\n",
    "            val_loss += loss.item() # 누적 손실 계산\n",
    "            val_accuracy += accuracy # 누적 정확도 계산\n",
    "\n",
    "    val_loss = val_loss/len(dataloader) # 평균 손실 계산\n",
    "    val_accuracy = val_accuracy/len(dataloader) # 평균 정확도 계산\n",
    "    return val_loss, val_accuracy\n",
    "\n",
    "\n",
    "# 7. 모델 학습 및 저장\n",
    "best_loss = 10000\n",
    "for epoch in range(epochs):\n",
    "    train_loss = train(model, optimizer, train_dataloader) # 학습 함수 호출\n",
    "    val_loss, val_accuracy = evaluation(model, valid_dataloader) # 평가 함수 호출\n",
    "    print(f\"Epoch {epoch + 1}: Train Loss: {train_loss:.4f} Val Loss: {val_loss:.4f} Val Accuracy {val_accuracy:.4f}\")\n",
    "\n",
    "    if val_loss < best_loss: # 손실이 감소했을 경우\n",
    "        best_loss = val_loss\n",
    "        torch.save(model.state_dict(), \"../models/GPT2ForSequenceClassification.pt\") # 모델 가중치 저장\n",
    "        print(\"Saved the model weights\")\n",
    "\n",
    "# 8. 테스트 데이터셋으로 최종 평가\n",
    "model = GPT2ForSequenceClassification.from_pretrained(\n",
    "    pretrained_model_name_or_path=\"gpt2\",\n",
    "    num_labels=2).to(device)\n",
    "model.config.pad_token_id = model.config.eos_token_id\n",
    "model.load_state_dict(torch.load(\"../models/GPT2ForSequenceClassification.pt\")) # 저장된 가중치 불러오기\n",
    "test_loss, test_accuracy = evaluation(model, test_dataloader) # 테스트 데이터로 최종 평가\n",
    "print(f\"Test Loss : {test_loss:.4f}\")\n",
    "print(f\"Test Accuracy : {test_accuracy:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyPD04mHoCi2h8sBHVranWJU",
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
