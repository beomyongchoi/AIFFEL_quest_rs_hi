{"cells":[{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HNrhZ5vLIOJo","executionInfo":{"status":"ok","timestamp":1754553445072,"user_tz":-540,"elapsed":18613,"user":{"displayName":"김형일","userId":"09633833925626345996"}},"outputId":"5c4d48f7-b6aa-4267-cfd8-2644d647e01d"},"id":"HNrhZ5vLIOJo","execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","execution_count":2,"id":"3abcd13d-0e43-4014-a772-d9f54ab82434","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3abcd13d-0e43-4014-a772-d9f54ab82434","executionInfo":{"status":"ok","timestamp":1754552090222,"user_tz":-540,"elapsed":3892,"user":{"displayName":"김형일","userId":"09633833925626345996"}},"outputId":"3fcaf07d-361e-4074-905b-e3ddfef8b0d1"},"outputs":[{"output_type":"stream","name":"stdout","text":["2.6.0+cu124\n"]}],"source":["import torch\n","print(torch.__version__)"]},{"cell_type":"code","execution_count":4,"id":"5d7f3db6-feaa-4a7e-8834-08634236b07e","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"5d7f3db6-feaa-4a7e-8834-08634236b07e","executionInfo":{"status":"ok","timestamp":1754552248946,"user_tz":-540,"elapsed":137649,"user":{"displayName":"김형일","userId":"09633833925626345996"}},"outputId":"6bf374a0-781c-4901-fc17-6d84351d8823"},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: torchdata in /usr/local/lib/python3.11/dist-packages (0.11.0)\n","Collecting torchtext==0.15.2\n","  Downloading torchtext-0.15.2-cp311-cp311-manylinux1_x86_64.whl.metadata (7.4 kB)\n","Collecting portalocker\n","  Downloading portalocker-3.2.0-py3-none-any.whl.metadata (8.7 kB)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from torchtext==0.15.2) (4.67.1)\n","Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from torchtext==0.15.2) (2.32.3)\n","Collecting torch==2.0.1 (from torchtext==0.15.2)\n","  Downloading torch-2.0.1-cp311-cp311-manylinux1_x86_64.whl.metadata (24 kB)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torchtext==0.15.2) (2.0.2)\n","Collecting torchdata\n","  Downloading torchdata-0.6.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (13 kB)\n","Requirement already satisfied: urllib3>=1.25 in /usr/local/lib/python3.11/dist-packages (from torchdata) (2.5.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch==2.0.1->torchtext==0.15.2) (3.18.0)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.11/dist-packages (from torch==2.0.1->torchtext==0.15.2) (4.14.1)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from torch==2.0.1->torchtext==0.15.2) (1.13.1)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch==2.0.1->torchtext==0.15.2) (3.5)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch==2.0.1->torchtext==0.15.2) (3.1.6)\n","Collecting nvidia-cuda-nvrtc-cu11==11.7.99 (from torch==2.0.1->torchtext==0.15.2)\n","  Downloading nvidia_cuda_nvrtc_cu11-11.7.99-2-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-cuda-runtime-cu11==11.7.99 (from torch==2.0.1->torchtext==0.15.2)\n","  Downloading nvidia_cuda_runtime_cu11-11.7.99-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n","Collecting nvidia-cuda-cupti-cu11==11.7.101 (from torch==2.0.1->torchtext==0.15.2)\n","  Downloading nvidia_cuda_cupti_cu11-11.7.101-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n","Collecting nvidia-cudnn-cu11==8.5.0.96 (from torch==2.0.1->torchtext==0.15.2)\n","  Downloading nvidia_cudnn_cu11-8.5.0.96-2-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n","Collecting nvidia-cublas-cu11==11.10.3.66 (from torch==2.0.1->torchtext==0.15.2)\n","  Downloading nvidia_cublas_cu11-11.10.3.66-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n","Collecting nvidia-cufft-cu11==10.9.0.58 (from torch==2.0.1->torchtext==0.15.2)\n","  Downloading nvidia_cufft_cu11-10.9.0.58-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-curand-cu11==10.2.10.91 (from torch==2.0.1->torchtext==0.15.2)\n","  Downloading nvidia_curand_cu11-10.2.10.91-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n","Collecting nvidia-cusolver-cu11==11.4.0.1 (from torch==2.0.1->torchtext==0.15.2)\n","  Downloading nvidia_cusolver_cu11-11.4.0.1-2-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n","Collecting nvidia-cusparse-cu11==11.7.4.91 (from torch==2.0.1->torchtext==0.15.2)\n","  Downloading nvidia_cusparse_cu11-11.7.4.91-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n","Collecting nvidia-nccl-cu11==2.14.3 (from torch==2.0.1->torchtext==0.15.2)\n","  Downloading nvidia_nccl_cu11-2.14.3-py3-none-manylinux1_x86_64.whl.metadata (1.8 kB)\n","Collecting nvidia-nvtx-cu11==11.7.91 (from torch==2.0.1->torchtext==0.15.2)\n","  Downloading nvidia_nvtx_cu11-11.7.91-py3-none-manylinux1_x86_64.whl.metadata (1.7 kB)\n","Collecting triton==2.0.0 (from torch==2.0.1->torchtext==0.15.2)\n","  Downloading triton-2.0.0-1-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.0 kB)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch==2.0.1->torchtext==0.15.2) (75.2.0)\n","Requirement already satisfied: wheel in /usr/local/lib/python3.11/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch==2.0.1->torchtext==0.15.2) (0.45.1)\n","Requirement already satisfied: cmake in /usr/local/lib/python3.11/dist-packages (from triton==2.0.0->torch==2.0.1->torchtext==0.15.2) (3.31.6)\n","Collecting lit (from triton==2.0.0->torch==2.0.1->torchtext==0.15.2)\n","  Downloading lit-18.1.8-py3-none-any.whl.metadata (2.5 kB)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->torchtext==0.15.2) (3.4.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->torchtext==0.15.2) (3.10)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->torchtext==0.15.2) (2025.7.14)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch==2.0.1->torchtext==0.15.2) (3.0.2)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy->torch==2.0.1->torchtext==0.15.2) (1.3.0)\n","Downloading torchtext-0.15.2-cp311-cp311-manylinux1_x86_64.whl (2.0 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m42.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading torchdata-0.6.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.6 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.6/4.6 MB\u001b[0m \u001b[31m37.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading torch-2.0.1-cp311-cp311-manylinux1_x86_64.whl (619.9 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m619.9/619.9 MB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cublas_cu11-11.10.3.66-py3-none-manylinux1_x86_64.whl (317.1 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m317.1/317.1 MB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cuda_cupti_cu11-11.7.101-py3-none-manylinux1_x86_64.whl (11.8 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.8/11.8 MB\u001b[0m \u001b[31m91.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cuda_nvrtc_cu11-11.7.99-2-py3-none-manylinux1_x86_64.whl (21.0 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.0/21.0 MB\u001b[0m \u001b[31m109.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cuda_runtime_cu11-11.7.99-py3-none-manylinux1_x86_64.whl (849 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m849.3/849.3 kB\u001b[0m \u001b[31m55.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cudnn_cu11-8.5.0.96-2-py3-none-manylinux1_x86_64.whl (557.1 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m557.1/557.1 MB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cufft_cu11-10.9.0.58-py3-none-manylinux2014_x86_64.whl (168.4 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m168.4/168.4 MB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_curand_cu11-10.2.10.91-py3-none-manylinux1_x86_64.whl (54.6 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.6/54.6 MB\u001b[0m \u001b[31m13.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cusolver_cu11-11.4.0.1-2-py3-none-manylinux1_x86_64.whl (102.6 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m102.6/102.6 MB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cusparse_cu11-11.7.4.91-py3-none-manylinux1_x86_64.whl (173.2 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m173.2/173.2 MB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_nccl_cu11-2.14.3-py3-none-manylinux1_x86_64.whl (177.1 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m177.1/177.1 MB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_nvtx_cu11-11.7.91-py3-none-manylinux1_x86_64.whl (98 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m98.6/98.6 kB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading triton-2.0.0-1-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (63.3 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.3/63.3 MB\u001b[0m \u001b[31m12.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading portalocker-3.2.0-py3-none-any.whl (22 kB)\n","Downloading lit-18.1.8-py3-none-any.whl (96 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m96.4/96.4 kB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: lit, portalocker, nvidia-nvtx-cu11, nvidia-nccl-cu11, nvidia-cusparse-cu11, nvidia-curand-cu11, nvidia-cufft-cu11, nvidia-cuda-runtime-cu11, nvidia-cuda-nvrtc-cu11, nvidia-cuda-cupti-cu11, nvidia-cublas-cu11, nvidia-cusolver-cu11, nvidia-cudnn-cu11, triton, torch, torchdata, torchtext\n","  Attempting uninstall: triton\n","    Found existing installation: triton 3.2.0\n","    Uninstalling triton-3.2.0:\n","      Successfully uninstalled triton-3.2.0\n","  Attempting uninstall: torch\n","    Found existing installation: torch 2.6.0+cu124\n","    Uninstalling torch-2.6.0+cu124:\n","      Successfully uninstalled torch-2.6.0+cu124\n","  Attempting uninstall: torchdata\n","    Found existing installation: torchdata 0.11.0\n","    Uninstalling torchdata-0.11.0:\n","      Successfully uninstalled torchdata-0.11.0\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","torchtune 0.6.1 requires torchdata==0.11.0, but you have torchdata 0.6.1 which is incompatible.\n","torchaudio 2.6.0+cu124 requires torch==2.6.0, but you have torch 2.0.1 which is incompatible.\n","torchvision 0.21.0+cu124 requires torch==2.6.0, but you have torch 2.0.1 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed lit-18.1.8 nvidia-cublas-cu11-11.10.3.66 nvidia-cuda-cupti-cu11-11.7.101 nvidia-cuda-nvrtc-cu11-11.7.99 nvidia-cuda-runtime-cu11-11.7.99 nvidia-cudnn-cu11-8.5.0.96 nvidia-cufft-cu11-10.9.0.58 nvidia-curand-cu11-10.2.10.91 nvidia-cusolver-cu11-11.4.0.1 nvidia-cusparse-cu11-11.7.4.91 nvidia-nccl-cu11-2.14.3 nvidia-nvtx-cu11-11.7.91 portalocker-3.2.0 torch-2.0.1 torchdata-0.6.1 torchtext-0.15.2 triton-2.0.0\n"]},{"output_type":"display_data","data":{"application/vnd.colab-display-data+json":{"pip_warning":{"packages":["torch","torchgen"]},"id":"8655623896894097a6651d52d23a27b8"}},"metadata":{}}],"source":["#토치 데이터 및 토치 텍스트 라이브러리 설치\n"," #Multi30k 데이터 세트(영-독 병렬 말뭉치 30,000개) 다운받기 위한 라이브러리\n","\n","!pip install torchdata torchtext==0.15.2 portalocker"]},{"cell_type":"code","source":["# 영어 독일어 Seq2SwqTransformer 클래스 다운로드\n","\n","!python -m spacy download de\n","!python -m spacy download en"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"NC_K2iCIJo1f","executionInfo":{"status":"ok","timestamp":1754552283554,"user_tz":-540,"elapsed":21270,"user":{"displayName":"김형일","userId":"09633833925626345996"}},"outputId":"2fbb5bc8-5338-45fb-9e7a-4c3714cce476"},"id":"NC_K2iCIJo1f","execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[38;5;3m⚠ As of spaCy v3.0, shortcuts like 'de' are deprecated. Please use the\n","full pipeline package name 'de_core_news_sm' instead.\u001b[0m\n","Collecting de-core-news-sm==3.8.0\n","  Downloading https://github.com/explosion/spacy-models/releases/download/de_core_news_sm-3.8.0/de_core_news_sm-3.8.0-py3-none-any.whl (14.6 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.6/14.6 MB\u001b[0m \u001b[31m114.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: de-core-news-sm\n","Successfully installed de-core-news-sm-3.8.0\n","\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n","You can now load the package via spacy.load('de_core_news_sm')\n","\u001b[38;5;3m⚠ Restart to reload dependencies\u001b[0m\n","If you are in a Jupyter or Colab notebook, you may need to restart Python in\n","order to load all the package's dependencies. You can do this by selecting the\n","'Restart kernel' or 'Restart runtime' option.\n","\u001b[38;5;3m⚠ As of spaCy v3.0, shortcuts like 'en' are deprecated. Please use the\n","full pipeline package name 'en_core_web_sm' instead.\u001b[0m\n","Collecting en-core-web-sm==3.8.0\n","  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.8.0/en_core_web_sm-3.8.0-py3-none-any.whl (12.8 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.8/12.8 MB\u001b[0m \u001b[31m97.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n","You can now load the package via spacy.load('en_core_web_sm')\n","\u001b[38;5;3m⚠ Restart to reload dependencies\u001b[0m\n","If you are in a Jupyter or Colab notebook, you may need to restart Python in\n","order to load all the package's dependencies. You can do this by selecting the\n","'Restart kernel' or 'Restart runtime' option.\n"]}]},{"cell_type":"code","source":["#torchtext와 호환을 맞추기 위해 numpy 다운그레이드\n","\n","!pip install numpy==1.26.4"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":468},"id":"SDIznWPaM11G","executionInfo":{"status":"ok","timestamp":1754552306700,"user_tz":-540,"elapsed":7655,"user":{"displayName":"김형일","userId":"09633833925626345996"}},"outputId":"4eb506a1-2c22-429a-8ce3-d3e7c0906140"},"id":"SDIznWPaM11G","execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting numpy==1.26.4\n","  Downloading numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n","\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/61.0 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.0/61.0 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.3 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.3/18.3 MB\u001b[0m \u001b[31m106.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: numpy\n","  Attempting uninstall: numpy\n","    Found existing installation: numpy 2.0.2\n","    Uninstalling numpy-2.0.2:\n","      Successfully uninstalled numpy-2.0.2\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","torchtune 0.6.1 requires torchdata==0.11.0, but you have torchdata 0.6.1 which is incompatible.\n","opencv-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\n","opencv-python-headless 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\n","opencv-contrib-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\n","torchvision 0.21.0+cu124 requires torch==2.6.0, but you have torch 2.0.1 which is incompatible.\n","thinc 8.3.6 requires numpy<3.0.0,>=2.0.0, but you have numpy 1.26.4 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed numpy-1.26.4\n"]},{"output_type":"display_data","data":{"application/vnd.colab-display-data+json":{"pip_warning":{"packages":["numpy"]},"id":"b4e86f62a35a48fea508c46346e95b79"}},"metadata":{}}]},{"cell_type":"code","execution_count":1,"id":"141624f9-a730-43f5-bdde-84113b08d8a2","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"141624f9-a730-43f5-bdde-84113b08d8a2","executionInfo":{"status":"ok","timestamp":1754552319087,"user_tz":-540,"elapsed":7026,"user":{"displayName":"김형일","userId":"09633833925626345996"}},"outputId":"385c0473-9ce3-45c9-dcf0-ae0e64ed1be8"},"outputs":[{"output_type":"stream","name":"stdout","text":["PyTorch version: 2.0.1+cu117\n","TorchText version: 0.15.2+cpu\n"]}],"source":["# torch torchtext import\n","\n","import torch\n","import torchtext\n","print(f\"PyTorch version: {torch.__version__}\")\n","print(f\"TorchText version: {torchtext.__version__}\")"]},{"cell_type":"code","source":["# Multi30k 데이터세트가 다운로드 되지 않고, Timeout 오류가 발생하는 경우, 다음 셀을 실행한다.\n","\n","from torchtext.datasets import multi30k\n","\n","\n","multi30k.URL[\"train\"] = \"https://raw.githubusercontent.com/neychev/small_DL_repo/master/datasets/Multi30k/training.tar.gz\"\n","multi30k.URL[\"valid\"] = \"https://raw.githubusercontent.com/neychev/small_DL_repo/master/datasets/Multi30k/validation.tar.gz\"\n","multi30k.URL[\"test\"] = \"https://raw.githubusercontent.com/neychev/small_DL_repo/master/datasets/Multi30k/mmt16_task1_test.tar.gz\""],"metadata":{"id":"NDaWSml9KgOH","executionInfo":{"status":"ok","timestamp":1754552338340,"user_tz":-540,"elapsed":5,"user":{"displayName":"김형일","userId":"09633833925626345996"}}},"id":"NDaWSml9KgOH","execution_count":6,"outputs":[]},{"cell_type":"code","source":["# 예제 7.2 데이터 세트 다운로드 및 전처리\n","\n","# Multi30k 데이터셋을 이용한 토큰화 및 어휘집(Vocab) 구축\n","from torchtext.datasets import Multi30k # Multi30k 데이터셋을 불러오는 역할\n","from torchtext.data.utils import get_tokenizer # 문장을 토큰으로 분리하는 토크나이저를 가져오는 역할\n","from torchtext.vocab import build_vocab_from_iterator # 토큰으로부터 어휘집을 구축하는 역할\n","\n","# 토큰을 생성하는 함수\n","def generate_tokens(text_iter, language): # text_iter는 데이터셋 이터레이터, language는 언어(de 또는 en)\n","    language_index = {SRC_LANGUAGE: 0, TGT_LANGUAGE: 1} # 소스(독일어)와 타겟(영어) 언어의 인덱스를 매핑\n","\n","    for text in text_iter: # 데이터셋의 각 문장 쌍을 순회\n","        yield token_transform[language](text[language_index[language]]) # 해당 언어의 텍스트를 토큰화하여 반환\n","\n","\n","SRC_LANGUAGE = \"de\" # 소스 언어를 독일어(de)로 설정\n","TGT_LANGUAGE = \"en\" # 타겟 언어를 영어(en)로 설정\n","UNK_IDX, PAD_IDX, BOS_IDX, EOS_IDX = 0, 1, 2, 3 # 특수 토큰의 인덱스를 정의\n","special_symbols = [\"<unk>\", \"<pad>\", \"<bos>\", \"<eos>\"] # 특수 토큰 리스트 정의\n","\n","token_transform = { # 언어별 토크나이저를 저장하는 딕셔너리\n","    SRC_LANGUAGE: get_tokenizer(\"spacy\", language=\"de_core_news_sm\"), # 독일어 텍스트를 토큰화할 spacy 토크나이저\n","    TGT_LANGUAGE: get_tokenizer(\"spacy\", language=\"en_core_web_sm\"), # 영어 텍스트를 토큰화할 spacy 토크나이저\n","}\n","print(\"Token Transform:\")\n","print(token_transform)\n","\n","vocab_transform = {} # 언어별 어휘집(vocab)을 저장하는 딕셔너리\n","for language in [SRC_LANGUAGE, TGT_LANGUAGE]: # 소스 언어와 타겟 언어를 순회\n","    train_iter = Multi30k(split=\"train\", language_pair=(SRC_LANGUAGE, TGT_LANGUAGE)) # 학습 데이터셋을 불러옴\n","    vocab_transform[language] = build_vocab_from_iterator( # 이터레이터로부터 어휘집 구축\n","        generate_tokens(train_iter, language), # 위에서 정의한 함수를 이용해 토큰을 생성\n","        min_freq=1, # 최소 빈도수를 1로 설정하여 모든 단어를 포함\n","        specials=special_symbols, # 특수 토큰을 어휘집에 추가\n","        special_first=True, # 특수 토큰을 어휘집 맨 앞에 위치\n","    )\n","\n","for language in [SRC_LANGUAGE, TGT_LANGUAGE]: # 소스 및 타겟 언어를 순회\n","    vocab_transform[language].set_default_index(UNK_IDX) # 어휘집에 없는 단어(UNK)에 대한 기본 인덱스 설정\n","\n","print(\"Vocab Transform:\")\n","print(vocab_transform)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"D2pIINv3KO7q","executionInfo":{"status":"ok","timestamp":1754552352368,"user_tz":-540,"elapsed":7338,"user":{"displayName":"김형일","userId":"09633833925626345996"}},"outputId":"bc668a70-25c8-4983-878a-c77d727e5762"},"id":"D2pIINv3KO7q","execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["Token Transform:\n","{'de': functools.partial(<function _spacy_tokenize at 0x78518daf0c20>, spacy=<spacy.lang.de.German object at 0x785170173c90>), 'en': functools.partial(<function _spacy_tokenize at 0x78518daf0c20>, spacy=<spacy.lang.en.English object at 0x78516f9b4dd0>)}\n","Vocab Transform:\n","{'de': Vocab(), 'en': Vocab()}\n"]}]},{"cell_type":"code","source":["!ls -al /root/.cache/torch/text/datasets/"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rkLSnp18LAyJ","executionInfo":{"status":"ok","timestamp":1754552358102,"user_tz":-540,"elapsed":167,"user":{"displayName":"김형일","userId":"09633833925626345996"}},"outputId":"1cc7833d-6e05-4d19-bbb6-8afe64a3f73f"},"id":"rkLSnp18LAyJ","execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["total 12\n","drwxr-xr-x 3 root root 4096 Aug  7 07:39 .\n","drwxr-xr-x 3 root root 4096 Aug  7 07:39 ..\n","drwxr-xr-x 2 root root 4096 Aug  7 07:39 Multi30k\n"]}]},{"cell_type":"code","source":["# Transformer 기반 번역 모델 (`Seq2SeqTransformer`) 구현\n","import math # 수학 연산을 위해 math 모듈을 가져옴\n","import torch # 텐서 연산을 위해 torch 모듈을 가져옴\n","from torch import nn # 신경망 모듈을 정의하기 위해 nn 모듈을 가져옴\n","\n","class PositionalEncoding(nn.Module): # 입력 시퀀스의 위치 정보를 추가하는 클래스\n","    def __init__(self, d_model, max_len, dropout=0.1): # d_model: 임베딩 차원, max_len: 시퀀스 최대 길이\n","        super().__init__()\n","        self.dropout = nn.Dropout(p=dropout) # 드롭아웃 레이어 정의\n","\n","        position = torch.arange(max_len).unsqueeze(1) # [max_len, 1] 크기의 위치 텐서 생성\n","        div_term = torch.exp( # 위치 인코딩의 분모 항 계산\n","            torch.arange(0, d_model, 2) * (-math.log(10000.0) / d_model)\n","        )\n","\n","        pe = torch.zeros(max_len, 1, d_model) # 위치 인코딩 벡터를 저장할 [max_len, 1, d_model] 크기의 텐서 생성\n","        pe[:, 0, 0::2] = torch.sin(position * div_term) # 짝수 인덱스에 sin 함수 적용\n","        pe[:, 0, 1::2] = torch.cos(position * div_term) # 홀수 인덱스에 cos 함수 적용\n","        self.register_buffer(\"pe\", pe) # pe 텐서를 모델의 버퍼로 등록하여 학습되지 않도록 설정\n","\n","    def forward(self, x): # 순전파 함수\n","        x = x + self.pe[: x.size(0)] # 입력 텐서 x에 위치 인코딩 pe를 더함\n","        return self.dropout(x) # 드롭아웃을 적용한 결과를 반환\n","\n","class TokenEmbedding(nn.Module): # 단어를 벡터로 변환하는 클래스\n","    def __init__(self, vocab_size, emb_size): # vocab_size: 어휘집 크기, emb_size: 임베딩 차원\n","        super().__init__()\n","        self.embedding = nn.Embedding(vocab_size, emb_size) # 임베딩 레이어 정의\n","        self.emb_size = emb_size # 임베딩 차원 저장\n","\n","    def forward(self, tokens): # 순전파 함수\n","        return self.embedding(tokens.long()) * math.sqrt(self.emb_size) # 임베딩 결과를 스케일링하여 반환\n","\n","class Seq2SeqTransformer(nn.Module): # Transformer 모델의 전체 구조를 정의하는 클래스\n","    def __init__( # 모델의 하이퍼파라미터 정의\n","        self,\n","        num_encoder_layers, # 인코더 레이어 수\n","        num_decoder_layers, # 디코더 레이어 수\n","        emb_size, # 임베딩 차원\n","        max_len, # 시퀀스 최대 길이\n","        nhead, # 멀티 헤드 어텐션의 헤드 수\n","        src_vocab_size, # 소스 언어 어휘집 크기\n","        tgt_vocab_size, # 타겟 언어 어휘집 크기\n","        dim_feedforward, # 피드포워드 네트워크의 차원\n","        dropout=0.1,\n","    ):\n","        super().__init__()\n","        self.src_tok_emb = TokenEmbedding(src_vocab_size, emb_size) # 소스 토큰 임베딩 레이어\n","        self.tgt_tok_emb = TokenEmbedding(tgt_vocab_size, emb_size) # 타겟 토큰 임베딩 레이어\n","        self.positional_encoding = PositionalEncoding( # 위치 인코딩 레이어\n","            d_model=emb_size, max_len=max_len, dropout=dropout\n","        )\n","        self.transformer = nn.Transformer( # PyTorch 내장 Transformer 모델\n","            d_model=emb_size,\n","            nhead=nhead,\n","            num_encoder_layers=num_encoder_layers,\n","            num_decoder_layers=num_decoder_layers,\n","            dim_feedforward=dim_feedforward,\n","            dropout=dropout,\n","        )\n","        self.generator = nn.Linear(emb_size, tgt_vocab_size) # 최종 출력을 생성하는 선형 레이어\n","\n","    def forward( # 전체 모델의 순전파 함수\n","        self,\n","        src, # 소스 시퀀스\n","        trg, # 타겟 시퀀스\n","        src_mask, # 소스 마스크\n","        tgt_mask, # 타겟 마스크\n","        src_padding_mask, # 소스 패딩 마스크\n","        tgt_padding_mask, # 타겟 패딩 마스크\n","        memory_key_padding_mask, # 메모리 키 패딩 마스크\n","    ):\n","        src_emb = self.positional_encoding(self.src_tok_emb(src)) # 소스 임베딩 + 위치 인코딩\n","        tgt_emb = self.positional_encoding(self.tgt_tok_emb(trg)) # 타겟 임베딩 + 위치 인코딩\n","        outs = self.transformer( # Transformer 인코더-디코더 실행\n","            src=src_emb,\n","            tgt=tgt_emb,\n","            src_mask=src_mask,\n","            tgt_mask=tgt_mask,\n","            memory_mask=None,\n","            src_key_padding_mask=src_padding_mask,\n","            tgt_key_padding_mask=tgt_padding_mask,\n","            memory_key_padding_mask=memory_key_padding_mask\n","        )\n","        return self.generator(outs) # 최종 예측 결과 반환\n","\n","    def encode(self, src, src_mask): # 인코더만 실행하는 함수\n","        return self.transformer.encoder(\n","            self.positional_encoding(self.src_tok_emb(src)), src_mask\n","        )\n","\n","    def decode(self, tgt, memory, tgt_mask): # 디코더만 실행하는 함수\n","        return self.transformer.decoder(\n","            self.positional_encoding(self.tgt_tok_emb(tgt)), memory, tgt_mask\n","        )"],"metadata":{"id":"JbCuZ3QcLvRa","executionInfo":{"status":"ok","timestamp":1754552361891,"user_tz":-540,"elapsed":5,"user":{"displayName":"김형일","userId":"09633833925626345996"}}},"id":"JbCuZ3QcLvRa","execution_count":9,"outputs":[]},{"cell_type":"code","source":["# Transformer 모델 초기화 및 구조 출력\n","from torch import optim # 최적화 알고리즘을 가져오는 역할\n","\n","BATCH_SIZE = 128 # 학습 시 사용할 배치 크기 정의\n","DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\" # GPU 사용 가능 여부에 따라 장치 설정\n","\n","model = Seq2SeqTransformer( # Seq2SeqTransformer 모델 인스턴스 생성\n","    num_encoder_layers=3, # 인코더 레이어 수: 3\n","    num_decoder_layers=3, # 디코더 레이어 수: 3\n","    emb_size=512, # 임베딩 및 모델 차원: 512\n","    max_len=512, # 시퀀스 최대 길이: 512\n","    nhead=8, # 멀티 헤드 어텐션의 헤드 수: 8\n","    src_vocab_size=len(vocab_transform[SRC_LANGUAGE]), # 소스 언어 어휘집 크기\n","    tgt_vocab_size=len(vocab_transform[TGT_LANGUAGE]), # 타겟 언어 어휘집 크기\n","    dim_feedforward=512, # 피드포워드 네트워크 차원: 512\n",").to(DEVICE) # 모델을 DEVICE에 할당 (GPU 또는 CPU)\n","\n","criterion = nn.CrossEntropyLoss(ignore_index=PAD_IDX).to(DEVICE) # 손실 함수 정의 (CrossEntropyLoss 사용) 및 DEVICE에 할당\n","# PAD_IDX를 무시하여 패딩 토큰에 대한 손실 계산을 방지\n","\n","optimizer = optim.Adam(model.parameters()) # 최적화 알고리즘(Adam) 정의\n","# 모델의 모든 학습 가능한 파라미터를 최적화 대상으로 지정\n","\n","for main_name, main_module in model.named_children(): # 모델의 최상위 모듈들을 순회\n","    print(main_name) # 모듈 이름 출력\n","    for sub_name, sub_module in main_module.named_children(): # 하위 모듈들을 순회\n","        print(\"└\", sub_name) # 하위 모듈 이름 출력\n","        for ssub_name, ssub_module in sub_module.named_children(): # 2단계 하위 모듈들을 순회\n","            print(\"│  └\", ssub_name) # 2단계 하위 모듈 이름 출력\n","            for sssub_name, sssub_module in ssub_module.named_children(): # 3단계 하위 모듈들을 순회\n","                print(\"│  │  └\", sssub_name) # 3단계 하위 모듈 이름 출력"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"kZS6h5KeMjWb","executionInfo":{"status":"ok","timestamp":1754552393095,"user_tz":-540,"elapsed":1604,"user":{"displayName":"김형일","userId":"09633833925626345996"}},"outputId":"efff265e-a47f-4682-e668-7b4e8cb0ef9d"},"id":"kZS6h5KeMjWb","execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["src_tok_emb\n","└ embedding\n","tgt_tok_emb\n","└ embedding\n","positional_encoding\n","└ dropout\n","transformer\n","└ encoder\n","│  └ layers\n","│  │  └ 0\n","│  │  └ 1\n","│  │  └ 2\n","│  └ norm\n","└ decoder\n","│  └ layers\n","│  │  └ 0\n","│  │  └ 1\n","│  │  └ 2\n","│  └ norm\n","generator\n"]}]},{"cell_type":"code","source":["from torchtext.datasets import multi30k\n","\n","multi30k.URL[\"train\"] = \"https://raw.githubusercontent.com/neychev/small_DL_repo/master/datasets/Multi30k/training.tar.gz\"\n","multi30k.URL[\"valid\"] = \"https://raw.githubusercontent.com/neychev/small_DL_repo/master/datasets/Multi30k/validation.tar.gz\"\n","multi30k.URL[\"test\"] = \"https://raw.githubusercontent.com/neychev/small_DL_repo/master/datasets/Multi30k/mmt16_task1_test.tar.gz\""],"metadata":{"id":"ormRXdHeO_H-","executionInfo":{"status":"ok","timestamp":1754552969132,"user_tz":-540,"elapsed":5,"user":{"displayName":"김형일","userId":"09633833925626345996"}}},"id":"ormRXdHeO_H-","execution_count":13,"outputs":[]},{"cell_type":"code","source":["# 예제 7.5 배치 데이터 생성\n","\n","# `DataLoader`를 사용한 데이터 전처리 및 배치 생성\n","from torch.utils.data import DataLoader # 데이터셋을 배치로 묶어주는 DataLoader 클래스를 가져옴\n","from torch.nn.utils.rnn import pad_sequence # 배치 내의 시퀀스 길이를 맞춰주는 pad_sequence 함수를 가져옴\n","\n","\n","def sequential_transforms(*transforms): # 여러 변환 함수를 순차적으로 적용하는 함수\n","    def func(txt_input): # 변환 함수를 반환하는 클로저(closure)\n","        for transform in transforms: # 전달된 변환 함수들을 순회\n","            txt_input = transform(txt_input) # 각 변환 함수를 순차적으로 적용\n","        return txt_input\n","    return func # 최종 변환 함수 반환\n","\n","def input_transform(token_ids): # 토큰 ID 리스트에 <bos>와 <eos>를 추가하는 함수\n","    return torch.cat( # 텐서들을 연결하여 반환\n","        (torch.tensor([BOS_IDX]), torch.tensor(token_ids), torch.tensor([EOS_IDX])) # [BOS_IDX] + 토큰 ID + [EOS_IDX]\n","    )\n","\n","def collator(batch): # DataLoader의 collate_fn으로 사용될 배치 생성 함수\n","    src_batch, tgt_batch = [], [] # 소스와 타겟 배치 리스트 초기화\n","    for src_sample, tgt_sample in batch: # 배치 내의 각 샘플(문장 쌍)을 순회\n","        src_batch.append(text_transform[SRC_LANGUAGE](src_sample.rstrip(\"\\n\"))) # 소스 문장을 전처리하여 리스트에 추가\n","        tgt_batch.append(text_transform[TGT_LANGUAGE](tgt_sample.rstrip(\"\\n\"))) # 타겟 문장을 전처리하여 리스트에 추가\n","\n","    src_batch = pad_sequence(src_batch, padding_value=PAD_IDX) # 소스 배치에 패딩 적용\n","    tgt_batch = pad_sequence(tgt_batch, padding_value=PAD_IDX) # 타겟 배치에 패딩 적용\n","    return src_batch, tgt_batch # 패딩된 텐서 배치 반환\n","\n","text_transform = {} # 언어별 전처리 파이프라인을 저장할 딕셔너리\n","for language in [SRC_LANGUAGE, TGT_LANGUAGE]: # 소스 언어와 타겟 언어를 순회\n","    text_transform[language] = sequential_transforms( # 언어별로 전처리 파이프라인 구성\n","        token_transform[language], # 1. 토큰화\n","        vocab_transform[language], # 2. 토큰을 정수 인덱스로 변환\n","        input_transform # 3. <bos>, <eos> 토큰 추가\n","    )\n","\n","data_iter = Multi30k(split=\"valid\", language_pair=(SRC_LANGUAGE, TGT_LANGUAGE)) # Multi30k 검증 데이터셋을 불러옴\n","dataloader = DataLoader(data_iter, batch_size=BATCH_SIZE, collate_fn=collator) # DataLoader 인스턴스 생성\n","source_tensor, target_tensor = next(iter(dataloader)) # DataLoader에서 첫 번째 배치 가져오기\n","\n","print(\"(source, target):\")\n","print(next(iter(data_iter))) # 첫 번째 데이터 쌍(문자열) 출력\n","\n","print(\"source_batch:\", source_tensor.shape)\n","print(source_tensor)\n","\n","print(\"target_batch:\", target_tensor.shape)\n","print(target_tensor)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ell04onUOeEK","executionInfo":{"status":"ok","timestamp":1754552977110,"user_tz":-540,"elapsed":8,"user":{"displayName":"김형일","userId":"09633833925626345996"}},"outputId":"ead1a574-6608-4c78-f6fb-6ea0e07187eb"},"id":"ell04onUOeEK","execution_count":14,"outputs":[{"output_type":"stream","name":"stdout","text":["(source, target):\n","('Eine Gruppe von Männern lädt Baumwolle auf einen Lastwagen', 'A group of men are loading cotton onto a truck')\n","source_batch: torch.Size([35, 128])\n","tensor([[   2,    2,    2,  ...,    2,    2,    2],\n","        [  14,    5,    5,  ...,    5,   21,    5],\n","        [  38,   12,   35,  ...,   12, 1750,   69],\n","        ...,\n","        [   1,    1,    1,  ...,    1,    1,    1],\n","        [   1,    1,    1,  ...,    1,    1,    1],\n","        [   1,    1,    1,  ...,    1,    1,    1]])\n","target_batch: torch.Size([30, 128])\n","tensor([[   2,    2,    2,  ...,    2,    2,    2],\n","        [   6,    6,    6,  ...,  250,   19,    6],\n","        [  39,   12,   35,  ...,   12, 3254,   61],\n","        ...,\n","        [   1,    1,    1,  ...,    1,    1,    1],\n","        [   1,    1,    1,  ...,    1,    1,    1],\n","        [   1,    1,    1,  ...,    1,    1,    1]])\n"]}]},{"cell_type":"code","source":["# 예제 7.6 어텐션 마스크 생성\n","\n","# Transformer 모델의 마스크 생성\n","def generate_square_subsequent_mask(s): # 디코더에 사용되는 사각형 마스크를 생성하는 함수\n","    mask = (torch.triu(torch.ones((s, s), device=DEVICE)) == 1).transpose(0, 1) # 상삼각행렬을 생성하여 마스크의 기본 형태를 만듦\n","    # torch.triu: 행렬의 상삼각 부분을 1로 채움\n","    # transpose(0, 1): 행과 열을 바꿔 하삼각행렬 형태로 만듦\n","    mask = (\n","        mask.float()\n","        .masked_fill(mask == 0, float(\"-inf\")) # 마스크가 0인 부분을 -inf로 채움 (어텐션 가중치를 0으로 만듦)\n","        .masked_fill(mask == 1, float(0.0)) # 마스크가 1인 부분을 0.0으로 채움 (어텐션이 가능하도록 함)\n","    )\n","    return mask\n","\n","def create_mask(src, tgt): # 소스(src)와 타겟(tgt) 시퀀스에 대한 모든 마스크를 생성하는 함수\n","    src_seq_len = src.shape[0] # 소스 시퀀스의 길이\n","    tgt_seq_len = tgt.shape[0] # 타겟 시퀀스의 길이\n","\n","    tgt_mask = generate_square_subsequent_mask(tgt_seq_len) # 디코더의 셀프 어텐션에 사용할 마스크 생성 (미래 토큰을 보지 않도록 함)\n","    src_mask = torch.zeros((src_seq_len, src_seq_len), device=DEVICE).type(torch.bool) # 인코더의 셀프 어텐션에 사용할 마스크 생성 (모든 토큰을 보도록 함)\n","    # 인코더는 모든 토큰을 볼 수 있으므로, 0으로 채워진 불리언 마스크를 사용\n","\n","    src_padding_mask = (src == PAD_IDX).transpose(0, 1) # 소스 시퀀스의 패딩 토큰 위치를 나타내는 불리언 마스크 생성\n","    tgt_padding_mask = (tgt == PAD_IDX).transpose(0, 1) # 타겟 시퀀스의 패딩 토큰 위치를 나타내는 불리언 마스크 생성\n","    return src_mask, tgt_mask, src_padding_mask, tgt_padding_mask\n","\n","target_input = target_tensor[:-1, :] # 타겟 시퀀스에서 마지막 토큰을 제외\n","target_out = target_tensor[1:, :] # 타겟 시퀀스에서 첫 번째 토큰을 제외\n","\n","source_mask, target_mask, source_padding_mask, target_padding_mask = create_mask(\n","    source_tensor, target_input) # 소스 및 타겟에 대한 모든 마스크 생성\n","\n","print(\"source_mask:\", source_mask.shape)\n","print(source_mask) # 인코더 마스크는 모두 False\n","print(\"target_mask:\", target_mask.shape)\n","print(target_mask) # 디코더 마스크는 하삼각 행렬 형태\n","print(\"source_padding_mask:\", source_padding_mask.shape)\n","print(source_padding_mask) # 소스 시퀀스의 패딩 위치는 True\n","print(\"target_padding_mask:\", target_padding_mask.shape)\n","print(target_padding_mask) # 타겟 시퀀스의 패딩 위치는 True"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"lKwpT7ifPco7","executionInfo":{"status":"ok","timestamp":1754552988583,"user_tz":-540,"elapsed":73,"user":{"displayName":"김형일","userId":"09633833925626345996"}},"outputId":"4475ef52-f31f-447d-fab4-76a5533209ee"},"id":"lKwpT7ifPco7","execution_count":15,"outputs":[{"output_type":"stream","name":"stdout","text":["source_mask: torch.Size([35, 35])\n","tensor([[False, False, False,  ..., False, False, False],\n","        [False, False, False,  ..., False, False, False],\n","        [False, False, False,  ..., False, False, False],\n","        ...,\n","        [False, False, False,  ..., False, False, False],\n","        [False, False, False,  ..., False, False, False],\n","        [False, False, False,  ..., False, False, False]], device='cuda:0')\n","target_mask: torch.Size([29, 29])\n","tensor([[0., -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf,\n","         -inf, -inf, -inf, -inf, -inf],\n","        [0., 0., -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf,\n","         -inf, -inf, -inf, -inf, -inf],\n","        [0., 0., 0., -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf,\n","         -inf, -inf, -inf, -inf, -inf],\n","        [0., 0., 0., 0., -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf,\n","         -inf, -inf, -inf, -inf, -inf],\n","        [0., 0., 0., 0., 0., -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf,\n","         -inf, -inf, -inf, -inf, -inf],\n","        [0., 0., 0., 0., 0., 0., -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf,\n","         -inf, -inf, -inf, -inf, -inf],\n","        [0., 0., 0., 0., 0., 0., 0., -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf,\n","         -inf, -inf, -inf, -inf, -inf],\n","        [0., 0., 0., 0., 0., 0., 0., 0., -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf,\n","         -inf, -inf, -inf, -inf, -inf],\n","        [0., 0., 0., 0., 0., 0., 0., 0., 0., -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf,\n","         -inf, -inf, -inf, -inf, -inf],\n","        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf,\n","         -inf, -inf, -inf, -inf, -inf],\n","        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf,\n","         -inf, -inf, -inf, -inf, -inf],\n","        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf,\n","         -inf, -inf, -inf, -inf, -inf],\n","        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf,\n","         -inf, -inf, -inf, -inf, -inf],\n","        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf,\n","         -inf, -inf, -inf, -inf, -inf],\n","        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf,\n","         -inf, -inf, -inf, -inf, -inf],\n","        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf,\n","         -inf, -inf, -inf, -inf, -inf],\n","        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., -inf, -inf, -inf, -inf, -inf, -inf, -inf,\n","         -inf, -inf, -inf, -inf, -inf],\n","        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., -inf, -inf, -inf, -inf, -inf, -inf,\n","         -inf, -inf, -inf, -inf, -inf],\n","        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., -inf, -inf, -inf, -inf, -inf,\n","         -inf, -inf, -inf, -inf, -inf],\n","        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., -inf, -inf, -inf, -inf,\n","         -inf, -inf, -inf, -inf, -inf],\n","        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., -inf, -inf, -inf,\n","         -inf, -inf, -inf, -inf, -inf],\n","        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., -inf, -inf,\n","         -inf, -inf, -inf, -inf, -inf],\n","        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., -inf,\n","         -inf, -inf, -inf, -inf, -inf],\n","        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","         -inf, -inf, -inf, -inf, -inf],\n","        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","         0., -inf, -inf, -inf, -inf],\n","        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","         0., 0., -inf, -inf, -inf],\n","        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","         0., 0., 0., -inf, -inf],\n","        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","         0., 0., 0., 0., -inf],\n","        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","         0., 0., 0., 0., 0.]], device='cuda:0')\n","source_padding_mask: torch.Size([128, 35])\n","tensor([[False, False, False,  ...,  True,  True,  True],\n","        [False, False, False,  ...,  True,  True,  True],\n","        [False, False, False,  ...,  True,  True,  True],\n","        ...,\n","        [False, False, False,  ...,  True,  True,  True],\n","        [False, False, False,  ...,  True,  True,  True],\n","        [False, False, False,  ...,  True,  True,  True]])\n","target_padding_mask: torch.Size([128, 29])\n","tensor([[False, False, False,  ...,  True,  True,  True],\n","        [False, False, False,  ...,  True,  True,  True],\n","        [False, False, False,  ...,  True,  True,  True],\n","        ...,\n","        [False, False, False,  ...,  True,  True,  True],\n","        [False, False, False,  ...,  True,  True,  True],\n","        [False, False, False,  ...,  True,  True,  True]])\n"]}]},{"cell_type":"code","source":["# 예제 7.7 모델 학습 및 평가\n","\n","# Transformer 모델 학습 및 검증 루프 구현\n","def run(model, optimizer, criterion, split): # 모델 학습 또는 검증을 수행하는 함수\n","    model.train() if split == \"train\" else model.eval() # split이 \"train\"이면 학습 모드, 아니면 평가 모드\n","    data_iter = Multi30k(split=split, language_pair=(SRC_LANGUAGE, TGT_LANGUAGE)) # 학습/검증 데이터셋 불러오기\n","    dataloader = DataLoader(data_iter, batch_size=BATCH_SIZE, collate_fn=collator) # DataLoader로 배치 생성\n","\n","    losses = 0 # 손실 누적 변수\n","    for source_batch, target_batch in dataloader: # 데이터로더에서 소스/타겟 배치 가져오기\n","        source_batch = source_batch.to(DEVICE) # 소스 배치를 GPU/CPU로 이동\n","        target_batch = target_batch.to(DEVICE) # 타겟 배치를 GPU/CPU로 이동\n","\n","        target_input = target_batch[:-1, :] # 타겟 시퀀스에서 마지막 토큰 제외 (모델 입력용)\n","        target_output = target_batch[1:, :] # 타겟 시퀀스에서 첫 번째 토큰 제외 (정답 레이블용)\n","\n","        src_mask, tgt_mask, src_padding_mask, tgt_padding_mask = create_mask( # 마스크 생성\n","            source_batch, target_input\n","        )\n","\n","        logits = model( # 모델에 데이터와 마스크를 입력하여 예측 결과(logits) 얻기\n","            src=source_batch,\n","            trg=target_input,\n","            src_mask=src_mask,\n","            tgt_mask=tgt_mask,\n","            src_padding_mask=src_padding_mask,\n","            tgt_padding_mask=tgt_padding_mask,\n","            memory_key_padding_mask=src_padding_mask,\n","        )\n","\n","        optimizer.zero_grad() # 옵티마이저의 그래디언트 초기화\n","        loss = criterion(logits.reshape(-1, logits.shape[-1]), target_output.reshape(-1)) # 손실 계산\n","        # logits을 (batch_size * seq_len, vocab_size) 형태로, target_output을 (batch_size * seq_len) 형태로 변환\n","        if split == \"train\": # 학습 모드일 경우\n","            loss.backward() # 역전파를 통해 그래디언트 계산\n","            optimizer.step() # 옵티마이저로 모델 파라미터 업데이트\n","        losses += loss.item() # 계산된 손실을 누적\n","\n","    return losses / len(list(dataloader)) # 평균 손실 반환\n","\n","for epoch in range(5): # 5번의 에포크 반복\n","    train_loss = run(model, optimizer, criterion, \"train\") # 학습 데이터로 run 함수 실행하여 학습 손실 계산\n","    val_loss = run(model, optimizer, criterion, \"valid\") # 검증 데이터로 run 함수 실행하여 검증 손실 계산\n","    print(f\"Epoch: {epoch+1}, Train loss: {train_loss:.3f}, Val loss: {val_loss:.3f}\") # 에포크별 손실 출력"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pxyO4KpdPo_B","executionInfo":{"status":"ok","timestamp":1754553237094,"user_tz":-540,"elapsed":245132,"user":{"displayName":"김형일","userId":"09633833925626345996"}},"outputId":"db283e9f-d2e0-43a5-ca51-4a5f429120b9"},"id":"pxyO4KpdPo_B","execution_count":16,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:4999: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 1, Train loss: 4.880, Val loss: 4.259\n","Epoch: 2, Train loss: 3.973, Val loss: 3.871\n","Epoch: 3, Train loss: 3.648, Val loss: 3.691\n","Epoch: 4, Train loss: 3.467, Val loss: 3.650\n","Epoch: 5, Train loss: 3.349, Val loss: 3.608\n"]}]},{"cell_type":"code","source":["# 예제 7.8 트랜스포머 모델 번역 결과\n","\n","# 탐욕적 디코딩(Greedy Decoding)을 이용한 번역 함수 구현\n","def greedy_decode(model, source_tensor, source_mask, max_len, start_symbol):\n","    # 인코더와 디코더를 이용해 번역 시퀀스를 생성하는 함수\n","    source_tensor = source_tensor.to(DEVICE) # 소스 텐서를 GPU/CPU로 이동\n","    source_mask = source_mask.to(DEVICE) # 소스 마스크를 GPU/CPU로 이동\n","\n","    memory = model.encode(source_tensor, source_mask) # 인코더에 소스 텐서를 입력하여 메모리(인코더 출력) 생성\n","    ys = torch.ones(1, 1).fill_(start_symbol).type(torch.long).to(DEVICE) # 디코더 입력의 시작 토큰(<bos>)\n","    for i in range(max_len - 1): # max_len까지 반복하여 토큰을 하나씩 생성\n","        memory = memory.to(DEVICE)\n","        target_mask = generate_square_subsequent_mask(ys.size(0)) # 디코더의 입력 시퀀스에 대한 마스크 생성\n","        target_mask = target_mask.type(torch.bool).to(DEVICE)\n","\n","        out = model.decode(ys, memory, target_mask) # 디코더에 현재까지의 출력 시퀀스와 메모리를 입력하여 다음 토큰 예측\n","        out = out.transpose(0, 1)\n","        prob = model.generator(out[:, -1]) # 마지막 토큰에 대한 예측 확률 분포를 얻음\n","        _, next_word = torch.max(prob, dim=1) # 확률이 가장 높은 다음 토큰을 선택 (Greedy)\n","        next_word = next_word.item() # 텐서에서 정수 값으로 변환\n","\n","        ys = torch.cat( # 예측된 토큰을 현재까지의 출력 시퀀스에 추가\n","            [ys, torch.ones(1, 1).type_as(source_tensor.data).fill_(next_word)], dim=0\n","        )\n","        if next_word == EOS_IDX: # 예측된 토큰이 문장 끝(<eos>)이면 반복문 종료\n","            break\n","    return ys # 최종 번역 결과 텐서 반환\n","\n","def translate(model, source_sentence):\n","    # 단일 문장을 번역하는 함수\n","    model.eval() # 모델을 평가 모드로 설정\n","    source_tensor = text_transform[SRC_LANGUAGE](source_sentence).view(-1, 1) # 소스 문장을 정수 텐서로 변환\n","    num_tokens = source_tensor.shape[0] # 소스 시퀀스의 토큰 수\n","    src_mask = (torch.zeros(num_tokens, num_tokens)).type(torch.bool) # 소스 마스크 생성\n","    tgt_tokens = greedy_decode( # 탐욕적 디코딩 함수를 호출하여 타겟 토큰 생성\n","        model, source_tensor, src_mask, max_len=num_tokens + 5, start_symbol=BOS_IDX\n","    ).flatten()\n","    output = vocab_transform[TGT_LANGUAGE].lookup_tokens(list(tgt_tokens.cpu().numpy()))[1:-1] # 토큰 인덱스를 단어로 변환\n","    return \" \".join(output) # 단어 리스트를 하나의 문자열로 결합하여 반환\n","\n","output_oov = translate(model, \"Eine Gruppe von Menschen steht vor einem Iglu .\") # 'Iglu'는 학습 데이터에 없을 수 있는 단어(OOV)\n","output = translate(model, \"Eine Gruppe von Menschen steht vor einem Gebäude .\") # 'Gebäude'는 일반적인 단어\n","print(output_oov)\n","print(output)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"SDs-JmopQNbt","executionInfo":{"status":"ok","timestamp":1754553268690,"user_tz":-540,"elapsed":10,"user":{"displayName":"김형일","userId":"09633833925626345996"}},"outputId":"717d46cf-6fd9-4b7b-a892-ad513774daf8"},"id":"SDs-JmopQNbt","execution_count":17,"outputs":[{"output_type":"stream","name":"stdout","text":["A man is sitting on a bench .\n","A man is sitting on a bench .\n"]}]},{"cell_type":"code","source":["%cd /content/drive/MyDrive/AIFFEL_quest_rs/Exploration/Quest01/\n","!ls"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"uNe7JndsjMbG","executionInfo":{"status":"ok","timestamp":1754553705049,"user_tz":-540,"elapsed":706,"user":{"displayName":"김형일","userId":"09633833925626345996"}},"outputId":"098379ec-fb7d-4c98-a570-6b68b600a96d"},"id":"uNe7JndsjMbG","execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/AIFFEL_quest_rs/Exploration/Quest01\n","colab_test.ipynb  pytoch_4.ipynb\n","data\t\t  pytoch_5_DatdAug.ipynb\n","datasets\t  pytoch_6_ImgClassification.ipynb\n","etc_teat\t  pytoch_7.ipynb\n","models\t\t  pytoch_8_TextDataPreProcessing.ipynb\n","non_linear.csv\t  pytorch_1.ipynb\n","Pokemon.csv\t  Quest01.ipynb\n","pytoch_2.ipynb\t  README.md\n","pytoch_3.ipynb\n"]}]},{"cell_type":"code","source":["!git config --global user.email \"nagujean@gmail.com\""],"metadata":{"id":"9SnkRXp-jsab","executionInfo":{"status":"ok","timestamp":1754553881775,"user_tz":-540,"elapsed":74,"user":{"displayName":"김형일","userId":"09633833925626345996"}}},"id":"9SnkRXp-jsab","execution_count":6,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"ITnfTiynj595"},"id":"ITnfTiynj595","execution_count":null,"outputs":[]},{"cell_type":"code","source":["!git add ."],"metadata":{"id":"KlCasnLti53O","executionInfo":{"status":"ok","timestamp":1754553736908,"user_tz":-540,"elapsed":29572,"user":{"displayName":"김형일","userId":"09633833925626345996"}}},"id":"KlCasnLti53O","execution_count":4,"outputs":[]},{"cell_type":"code","source":["!git commit -m \"add\""],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"kWNqQjzPjQ72","executionInfo":{"status":"ok","timestamp":1754553809478,"user_tz":-540,"elapsed":69256,"user":{"displayName":"김형일","userId":"09633833925626345996"}},"outputId":"44a1aca4-a0da-4766-81fc-72d71aec5d99"},"id":"kWNqQjzPjQ72","execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["Author identity unknown\n","\n","*** Please tell me who you are.\n","\n","Run\n","\n","  git config --global user.email \"you@example.com\"\n","  git config --global user.name \"Your Name\"\n","\n","to set your account's default identity.\n","Omit --global to set the identity only in this repository.\n","\n","fatal: unable to auto-detect email address (got 'root@f68476b7e764.(none)')\n"]}]},{"cell_type":"code","source":["!git push origin main"],"metadata":{"id":"dHvOh3RejSFp"},"id":"dHvOh3RejSFp","execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"znofbubXjR1I"},"id":"znofbubXjR1I","execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"vsxj5LkAjRPx"},"id":"vsxj5LkAjRPx","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.12.11"},"colab":{"provenance":[],"gpuType":"T4"},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":5}