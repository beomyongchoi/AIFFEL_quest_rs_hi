{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1452,
     "status": "ok",
     "timestamp": 1754580654080,
     "user": {
      "displayName": "김형일",
      "userId": "09633833925626345996"
     },
     "user_tz": -540
    },
    "id": "Y52Im2WkqPKu",
    "outputId": "98c71488-27d5-4967-dc8c-db23dec87062"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 195,
     "status": "ok",
     "timestamp": 1754580657045,
     "user": {
      "displayName": "김형일",
      "userId": "09633833925626345996"
     },
     "user_tz": -540
    },
    "id": "y_PR9SQAqgOk",
    "outputId": "98e8f2d3-a167-4461-f6a2-bdf6dc181e02"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Errno 2] No such file or directory: '/content/drive/MyDrive/AIFFEL_quest_rs/Exploration/Quest01/'\n",
      "/home/jovyan/work/workplace/AIFFEL_quest_rs/Exploration/Quest01/etc_teat\n",
      "Gpt-2.ipynb  Transformer_Translator.ipynb  Untitled0.ipynb  Untitled1.ipynb\n"
     ]
    }
   ],
   "source": [
    "%cd /content/drive/MyDrive/AIFFEL_quest_rs/Exploration/Quest01/\n",
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 8759,
     "status": "ok",
     "timestamp": 1754579663459,
     "user": {
      "displayName": "김형일",
      "userId": "09633833925626345996"
     },
     "user_tz": -540
    },
    "id": "4bx2MdIcq2Vg",
    "outputId": "3398ec16-2cbe-49b6-e10a-3cc7b9fcc040"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: Korpora in /opt/conda/lib/python3.12/site-packages (0.2.0)\n",
      "Requirement already satisfied: dataclasses>=0.6 in /opt/conda/lib/python3.12/site-packages (from Korpora) (0.6)\n",
      "Requirement already satisfied: numpy>=1.18.0 in /opt/conda/lib/python3.12/site-packages (from Korpora) (2.2.6)\n",
      "Requirement already satisfied: tqdm>=4.46.0 in /opt/conda/lib/python3.12/site-packages (from Korpora) (4.67.1)\n",
      "Requirement already satisfied: requests>=2.20.0 in /opt/conda/lib/python3.12/site-packages (from Korpora) (2.32.4)\n",
      "Requirement already satisfied: xlrd>=1.2.0 in /opt/conda/lib/python3.12/site-packages (from Korpora) (2.0.1)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /opt/conda/lib/python3.12/site-packages (from requests>=2.20.0->Korpora) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.12/site-packages (from requests>=2.20.0->Korpora) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.12/site-packages (from requests>=2.20.0->Korpora) (2.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.12/site-packages (from requests>=2.20.0->Korpora) (2025.6.15)\n"
     ]
    }
   ],
   "source": [
    "!pip install Korpora"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 10127,
     "status": "ok",
     "timestamp": 1754579685884,
     "user": {
      "displayName": "김형일",
      "userId": "09633833925626345996"
     },
     "user_tz": -540
    },
    "id": "BElht8xWqd2x",
    "outputId": "59560864-7af7-4577-fa11-758cafbf177c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    Korpora 는 다른 분들이 연구 목적으로 공유해주신 말뭉치들을\n",
      "    손쉽게 다운로드, 사용할 수 있는 기능만을 제공합니다.\n",
      "\n",
      "    말뭉치들을 공유해 주신 분들에게 감사드리며, 각 말뭉치 별 설명과 라이센스를 공유 드립니다.\n",
      "    해당 말뭉치에 대해 자세히 알고 싶으신 분은 아래의 description 을 참고,\n",
      "    해당 말뭉치를 연구/상용의 목적으로 이용하실 때에는 아래의 라이센스를 참고해 주시기 바랍니다.\n",
      "\n",
      "    # Description\n",
      "    Author : e9t@github\n",
      "    Repository : https://github.com/e9t/nsmc\n",
      "    References : www.lucypark.kr/docs/2015-pyconkr/#39\n",
      "\n",
      "    Naver sentiment movie corpus v1.0\n",
      "    This is a movie review dataset in the Korean language.\n",
      "    Reviews were scraped from Naver Movies.\n",
      "\n",
      "    The dataset construction is based on the method noted in\n",
      "    [Large movie review dataset][^1] from Maas et al., 2011.\n",
      "\n",
      "    [^1]: http://ai.stanford.edu/~amaas/data/sentiment/\n",
      "\n",
      "    # License\n",
      "    CC0 1.0 Universal (CC0 1.0) Public Domain Dedication\n",
      "    Details in https://creativecommons.org/publicdomain/zero/1.0/\n",
      "\n",
      "[Korpora] Corpus `nsmc` is already installed at /home/jovyan/Korpora/nsmc/ratings_train.txt\n",
      "[Korpora] Corpus `nsmc` is already installed at /home/jovyan/Korpora/nsmc/ratings_test.txt\n"
     ]
    }
   ],
   "source": [
    "# 네이버 영화 리뷰 데이터셋(NSMC) 로드 및 샘플링\n",
    "import numpy as np # 넘파이 라이브러리 임포트\n",
    "import pandas as pd # 판다스 라이브러리 임포트\n",
    "from Korpora import Korpora # Korpora 라이브러리에서 Korpora 클래스 임포트\n",
    "\n",
    "corpus = Korpora.load(\"nsmc\") # 'nsmc' 데이터셋을 불러와 corpus 변수에 저장\n",
    "# Korpora.load() 함수는 'nsmc' 데이터셋을 불러오는 역할을 합니다.\n",
    "\n",
    "df = pd.DataFrame(corpus.test).sample(20000, random_state=42) # 데이터프레임 생성 및 샘플링\n",
    "# corpus.test는 테스트 데이터셋을 의미합니다.\n",
    "# pd.DataFrame()을 이용해 테스트 데이터를 데이터프레임으로 변환합니다.\n",
    "# .sample(20000, random_state=42)를 통해 전체 테스트 데이터 중 20,000개를 무작위로 추출하되,\n",
    "# random_state=42를 설정하여 매번 동일한 결과를 얻도록 합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tabulate in /opt/conda/lib/python3.12/site-packages (0.9.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install tabulate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 68,
     "status": "ok",
     "timestamp": 1754579688730,
     "user": {
      "displayName": "김형일",
      "userId": "09633833925626345996"
     },
     "user_tz": -540
    },
    "id": "KfhSv283rDSo",
    "outputId": "0d58baa0-60bf-4489-d9ab-7c7143cef0a2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|       | text                                                     |   label |\n",
      "|------:|:---------------------------------------------------------|--------:|\n",
      "| 26891 | 역시 코믹액션은 성룡, 홍금보, 원표 삼인방이 최고지!!     |       1 |\n",
      "| 25024 | 점수 후하게 줘야것네 별 반개~                            |       0 |\n",
      "| 11666 | 오랜만에 느낄수 있는 [감독] 구타욕구.                    |       0 |\n",
      "| 40303 | 본지는 좀 됬지만 극장서 돈주고 본게 아직까지 아까운 영화 |       0 |\n",
      "| 18010 | 징키스칸이란 소재를 가지고 이것밖에 못만드냐             |       0 |\n",
      "Training Data Size : 12000\n",
      "Validation Data Size : 4000\n",
      "Testing Data Size : 4000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.12/site-packages/numpy/_core/fromnumeric.py:57: FutureWarning: 'DataFrame.swapaxes' is deprecated and will be removed in a future version. Please use 'DataFrame.transpose' instead.\n",
      "  return bound(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "# 데이터프레임을 훈련, 검증, 테스트 데이터셋으로 분할\n",
    "# df.sample(frac=1, random_state=42) : 데이터프레임 'df'의 모든 행을 무작위로 섞습니다.\n",
    "#                                      frac=1은 전체 데이터를 의미하고, random_state는 재현성을 위해 고정합니다.\n",
    "# np.split(...) : 섞인 데이터를 지정된 비율로 나눕니다.\n",
    "# [int(0.6 * len(df)), int(0.8 * len(df))] : 분할 기준이 되는 인덱스를 계산합니다.\n",
    "#                                            전체 길이의 60% 지점과 80% 지점을 기준으로 데이터를 3개로 나눕니다.\n",
    "train, valid, test = np.split(\n",
    "    df.sample(frac=1, random_state=42), [int(0.6 * len(df)), int(0.8 * len(df))])\n",
    "\n",
    "# print(train.head(5).to_markdown()) : 훈련 데이터셋의 상위 5개를 마크다운 형식으로 출력합니다.\n",
    "# print(f\"Training Data Size : {len(train)}\") : 훈련 데이터셋의 크기를 출력합니다.\n",
    "# print(f\"Validation Data Size : {len(valid)}\") : 검증 데이터셋의 크기를 출력합니다.\n",
    "# print(f\"Testing Data Size : {len(test)}\") : 테스트 데이터셋의 크기를 출력합니다.\n",
    "print(train.head(5).to_markdown())\n",
    "print(f\"Training Data Size : {len(train)}\")\n",
    "print(f\"Validation Data Size : {len(valid)}\")\n",
    "print(f\"Testing Data Size : {len(test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 35146,
     "status": "ok",
     "timestamp": 1754579727154,
     "user": {
      "displayName": "김형일",
      "userId": "09633833925626345996"
     },
     "user_tz": -540
    },
    "id": "sl2OB5kvrKX-",
    "outputId": "f2a0c16b-afe6-4712-8530-f4b21fc12d16"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor([   101,  58466,   9812, 118956, 119122,  59095,  10892,   9434, 118888,\n",
      "           117,   9992,  40032,  30005,    117,   9612,  37824,   9410,  12030,\n",
      "         42337,  10739,  83491,  12508,    106,    106,    102,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0],\n",
      "       device='cuda:0'), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0], device='cuda:0'), tensor(1, device='cuda:0'))\n"
     ]
    }
   ],
   "source": [
    "# BERT 모델 학습을 위한 데이터 전처리 및 데이터로더 생성\n",
    "import torch # 파이토치 라이브러리 임포트\n",
    "from transformers import BertTokenizer # Hugging Face의 transformers 라이브러리에서 BertTokenizer를 임포트합니다.\n",
    "from torch.utils.data import TensorDataset, DataLoader # 파이토치 데이터 유틸리티를 임포트합니다.\n",
    "from torch.utils.data import RandomSampler, SequentialSampler # 데이터 샘플러를 임포트합니다.\n",
    "\n",
    "# 데이터셋을 만드는 함수를 정의합니다.\n",
    "def make_dataset(data, tokenizer, device):\n",
    "    # 입력 데이터를 토크나이징합니다.\n",
    "    tokenized = tokenizer(\n",
    "        text=data.text.tolist(), # 데이터프레임의 'text' 컬럼을 리스트로 변환하여 입력으로 사용합니다.\n",
    "        padding=\"longest\", # 모든 시퀀스의 길이를 가장 긴 시퀀스에 맞춰 패딩합니다.\n",
    "        truncation=True, # 시퀀스 길이가 최대 길이를 초과하면 잘라냅니다.\n",
    "        return_tensors=\"pt\" # 파이토치 텐서 형태로 반환합니다.\n",
    "    )\n",
    "    # 토큰화된 데이터에서 input_ids(토큰 인덱스)를 추출하여 device로 이동시킵니다.\n",
    "    input_ids = tokenized[\"input_ids\"].to(device)\n",
    "    # 토큰화된 데이터에서 attention_mask(어텐션 마스크)를 추출하여 device로 이동시킵니다.\n",
    "    attention_mask = tokenized[\"attention_mask\"].to(device)\n",
    "    # 데이터프레임의 'label' 컬럼을 파이토치 텐서로 변환하고 device로 이동시킵니다.\n",
    "    labels = torch.tensor(data.label.values, dtype=torch.long).to(device)\n",
    "    # input_ids, attention_mask, labels를 묶어 TensorDataset 객체를 반환합니다.\n",
    "    return TensorDataset(input_ids, attention_mask, labels)\n",
    "\n",
    "# 데이터로더를 생성하는 함수를 정의합니다.\n",
    "def get_datalodader(dataset, sampler, batch_size):\n",
    "    # 데이터셋에 적용할 샘플러(Random 또는 Sequential)를 생성합니다.\n",
    "    data_sampler = sampler(dataset)\n",
    "    # 데이터셋, 샘플러, 배치 사이즈를 이용하여 DataLoader를 생성합니다.\n",
    "    dataloader = DataLoader(dataset, sampler=data_sampler, batch_size=batch_size)\n",
    "    # 생성된 데이터로더를 반환합니다.\n",
    "    return dataloader\n",
    "\n",
    "# 하이퍼파라미터를 설정합니다.\n",
    "epochs = 5\n",
    "batch_size = 32\n",
    "# GPU 사용 가능 여부를 확인하여 device를 설정합니다.\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "# BERT 토크나이저를 로드합니다.\n",
    "# pretrained_model_name_or_path: 사전 학습된 모델의 이름을 지정합니다. (다국어 BERT 모델)\n",
    "# do_lower_case: 소문자화 여부를 결정합니다. (False는 소문자화하지 않음)\n",
    "tokenizer = BertTokenizer.from_pretrained(\n",
    "    pretrained_model_name_or_path=\"bert-base-multilingual-cased\",\n",
    "    do_lower_case=False)\n",
    "\n",
    "# make_dataset 함수를 사용하여 훈련, 검증, 테스트 데이터셋을 생성합니다.\n",
    "train_dataset = make_dataset(train, tokenizer, device)\n",
    "valid_dataset = make_dataset(valid, tokenizer, device)\n",
    "test_dataset = make_dataset(test, tokenizer, device)\n",
    "\n",
    "# get_datalodader 함수를 사용하여 각 데이터셋에 대한 데이터로더를 생성합니다.\n",
    "# 훈련 데이터로더는 RandomSampler를 사용하여 데이터를 무작위로 섞습니다.\n",
    "train_dataloader = get_datalodader(train_dataset, RandomSampler, batch_size)\n",
    "# 검증 및 테스트 데이터로더는 SequentialSampler를 사용하여 데이터를 순차적으로 사용합니다.\n",
    "valid_dataloader = get_datalodader(valid_dataset, SequentialSampler, batch_size)\n",
    "test_dataloader = get_datalodader(test_dataset, SequentialSampler, batch_size)\n",
    "\n",
    "# 훈련 데이터셋의 첫 번째 요소를 출력합니다.\n",
    "print(train_dataset[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /opt/conda/lib/python3.12/site-packages (4.55.0)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.12/site-packages (from transformers) (3.13.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in /opt/conda/lib/python3.12/site-packages (from transformers) (0.34.3)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.12/site-packages (from transformers) (2.2.6)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.12/site-packages (from transformers) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.12/site-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.12/site-packages (from transformers) (2025.7.34)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.12/site-packages (from transformers) (2.32.4)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /opt/conda/lib/python3.12/site-packages (from transformers) (0.21.4)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /opt/conda/lib/python3.12/site-packages (from transformers) (0.6.1)\n",
      "Requirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.12/site-packages (from transformers) (4.67.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.12/site-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (2025.5.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.12/site-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (4.14.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /opt/conda/lib/python3.12/site-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (1.1.7)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /opt/conda/lib/python3.12/site-packages (from requests->transformers) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.12/site-packages (from requests->transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.12/site-packages (from requests->transformers) (2.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.12/site-packages (from requests->transformers) (2025.6.15)\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'BertForSequenceClassification' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 7\u001b[39m\n\u001b[32m      4\u001b[39m device = \u001b[33m\"\u001b[39m\u001b[33mcuda\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m torch.cuda.is_available() \u001b[38;5;28;01melse\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mcpu\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m      6\u001b[39m \u001b[38;5;66;03m# 이제 device 변수를 사용할 수 있습니다.\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m7\u001b[39m model = \u001b[43mBertForSequenceClassification\u001b[49m.from_pretrained(\n\u001b[32m      8\u001b[39m     pretrained_model_name_or_path=\u001b[33m\"\u001b[39m\u001b[33mbert-base-multilingual-cased\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m      9\u001b[39m     num_labels=\u001b[32m2\u001b[39m).to(device)\n",
      "\u001b[31mNameError\u001b[39m: name 'BertForSequenceClassification' is not defined"
     ]
    }
   ],
   "source": [
    "# import torch\n",
    "\n",
    "# # GPU 사용 가능 여부를 확인하여 device 변수를 정의합니다.\n",
    "# device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "# # 이제 device 변수를 사용할 수 있습니다.\n",
    "# model = BertForSequenceClassification.from_pretrained(\n",
    "#     pretrained_model_name_or_path=\"bert-base-multilingual-cased\",\n",
    "#     num_labels=2).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 22325,
     "status": "ok",
     "timestamp": 1754579782874,
     "user": {
      "displayName": "김형일",
      "userId": "09633833925626345996"
     },
     "user_tz": -540
    },
    "id": "o39qoX15rcrp",
    "outputId": "f0f970e2-bb69-468c-d389-c7a817494adc"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-multilingual-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# BERT 모델 및 옵티마이저 설정\n",
    "from torch import optim # 파이토치에서 옵티마이저 모듈을 임포트합니다.\n",
    "from transformers import BertForSequenceClassification # Hugging Face의 transformers 라이브러리에서 BertForSequenceClassification 클래스를 임포트합니다.\n",
    "\n",
    "# BertForSequenceClassification 모델을 불러옵니다.\n",
    "model = BertForSequenceClassification.from_pretrained(\n",
    "    pretrained_model_name_or_path=\"bert-base-multilingual-cased\", # 다국어 BERT 모델을 사용합니다.\n",
    "    num_labels=2).to(device) # 분류할 라벨의 개수를 2개(긍정/부정)로 설정하고, 모델을 지정된 device(CPU 또는 GPU)로 이동시킵니다.\n",
    "    # .to(device)는 모델을 GPU와 같은 가속기로 보내 연산을 빠르게 합니다.\n",
    "\n",
    "# AdamW 옵티마이저를 정의합니다.\n",
    "optimizer = optim.AdamW(model.parameters(), lr=1e-5, eps=1e-8)\n",
    "# model.parameters(): 모델의 모든 학습 가능한 파라미터를 옵티마이저에 전달합니다.\n",
    "# lr=1e-5: 학습률(learning rate)을 0.00001로 설정합니다.\n",
    "# eps=1e-8: 부동 소수점 연산에서 0으로 나누는 것을 방지하기 위한 작은 상수(epsilon)를 설정합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1754579800886,
     "user": {
      "displayName": "김형일",
      "userId": "09633833925626345996"
     },
     "user_tz": -540
    },
    "id": "p0RIic5Vrfon",
    "outputId": "43d7e287-de17-4517-ac69-768302457a11"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bert\n",
      "└ embeddings\n",
      "│  └ word_embeddings\n",
      "│  └ position_embeddings\n",
      "│  └ token_type_embeddings\n",
      "│  └ LayerNorm\n",
      "│  └ dropout\n",
      "└ encoder\n",
      "│  └ layer\n",
      "│  │  └ 0\n",
      "│  │  └ 1\n",
      "│  │  └ 2\n",
      "│  │  └ 3\n",
      "│  │  └ 4\n",
      "│  │  └ 5\n",
      "│  │  └ 6\n",
      "│  │  └ 7\n",
      "│  │  └ 8\n",
      "│  │  └ 9\n",
      "│  │  └ 10\n",
      "│  │  └ 11\n",
      "└ pooler\n",
      "│  └ dense\n",
      "│  └ activation\n",
      "dropout\n",
      "classifier\n"
     ]
    }
   ],
   "source": [
    "# BERT 모델의 계층 구조 출력\n",
    "# model.named_children(): 모델의 직계 자식 모듈들을 (이름, 모듈) 쌍으로 반환합니다.\n",
    "for main_name, main_module in model.named_children():\n",
    "    print(main_name) # 'bert'와 'dropout', 'classifier' 같은 최상위 모듈의 이름을 출력합니다.\n",
    "    for sub_name, sub_module in main_module.named_children():\n",
    "        print(\"└\", sub_name) # 최상위 모듈의 하위 모듈 이름을 출력합니다. (예: 'bert' 모듈 아래의 'embeddings', 'encoder', 'pooler')\n",
    "        for ssub_name, ssub_module in sub_module.named_children():\n",
    "            print(\"│  └\", ssub_name) # 하위 모듈의 하위 모듈 이름을 출력합니다. (예: 'encoder' 모듈 아래의 'layer')\n",
    "            for sssub_name, sssub_module in ssub_module.named_children():\n",
    "                print(\"│  │  └\", sssub_name) # 가장 깊은 계층의 모듈 이름을 출력합니다. (예: 'layer' 모듈 아래의 '0'부터 '11'까지)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 67,
     "referenced_widgets": [
      "c95ec3d4a3bd4d51923251edea4db052",
      "4f00601b2c97405388761fbb58e24d1c",
      "8321b303f8e0414c8c81c8c50e6d7928",
      "4b7025d4582b4a16937086360446cba1",
      "ad98cd2b440a49e6946e8ad6ef32f63e",
      "b162cfed23de47b9b27ba28f09e04bda",
      "f8dc43ed87cd49b09b0f59347352f757",
      "cf74795110b54723b63cf784846c3e66",
      "14f1b67d9e8843e2a0bdce02aa5ef22f",
      "a758c6a577ff42998ff1be3ddfa1d0e2",
      "217a2c5e01f1492d807e36bf3a433430"
     ]
    },
    "id": "mjoyzuHNr24T",
    "outputId": "90cffdd6-54b3-48fa-9898-72bb51f2f5fd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Epoch 1/5 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "758402a2cac8474b8ed80171f7701721",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/375 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7cdc39aa968b4c2a97d3cb5a134909ca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluation:   0%|          | 0/125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train Loss: 0.5755 Val Loss: 0.4578 Val Accuracy 0.7870\n",
      "Saved the model weights\n",
      "--- Epoch 2/5 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4b877891708e4c9085537f9d4d25d1e9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/375 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6af6deb849dc443c8c9d6e56f340f537",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluation:   0%|          | 0/125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: Train Loss: 0.4284 Val Loss: 0.4203 Val Accuracy 0.8075\n",
      "Saved the model weights\n",
      "--- Epoch 3/5 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a7e9cf83c9b94c3d99c10269d200c2e7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/375 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec5eb9fd79d04dc4809363f65cc18cd6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluation:   0%|          | 0/125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: Train Loss: 0.3421 Val Loss: 0.4070 Val Accuracy 0.8160\n",
      "Saved the model weights\n",
      "--- Epoch 4/5 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2cde7bd20dd54055a147f8443a28d801",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/375 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d57100a2298549a8b6d5dee7bb2dc455",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluation:   0%|          | 0/125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: Train Loss: 0.2662 Val Loss: 0.4673 Val Accuracy 0.8153\n",
      "--- Epoch 5/5 ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a705ef0d27bd40989e8caef671a3b224",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/375 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "45cce17ed55a4f75aab2ca2de88172bf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluation:   0%|          | 0/125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5: Train Loss: 0.2136 Val Loss: 0.4797 Val Accuracy 0.8150\n"
     ]
    }
   ],
   "source": [
    "# BERT 모델 훈련, 검증 및 가중치 저장\n",
    "# BERT 모델 훈련, 검증 및 가중치 저장\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "from tqdm.auto import tqdm # tqdm 라이브러리 임포트\n",
    "from transformers import BertTokenizer\n",
    "\n",
    "\n",
    "# 하이퍼파라미터와 디바이스 설정\n",
    "epochs = 5\n",
    "batch_size = 32\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "# tokenizer 정의\n",
    "tokenizer = BertTokenizer.from_pretrained(\n",
    "    pretrained_model_name_or_path=\"bert-base-multilingual-cased\",\n",
    "    do_lower_case=False)\n",
    "\n",
    "# 데이터셋 및 데이터로더 생성\n",
    "train_dataset = make_dataset(train, tokenizer, device)\n",
    "train_dataloader = get_datalodader(train_dataset, RandomSampler, batch_size)\n",
    "valid_dataset = make_dataset(valid, tokenizer, device)\n",
    "valid_dataloader = get_datalodader(valid_dataset, SequentialSampler, batch_size)\n",
    "test_dataset = make_dataset(test, tokenizer, device)\n",
    "test_dataloader = get_datalodader(test_dataset, SequentialSampler, batch_size)\n",
    "\n",
    "\n",
    "# 정확도를 계산하는 함수입니다.\n",
    "def calc_accuracy(preds, labels):\n",
    "    # 예측값(preds)의 가장 높은 확률을 가진 클래스의 인덱스를 가져와 1차원 배열로 만듭니다.\n",
    "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
    "    # 정답 라벨(labels)을 1차원 배열로 만듭니다.\n",
    "    labels_flat = labels.flatten()\n",
    "    # 예측값과 정답이 일치하는 비율을 계산하여 반환합니다.\n",
    "    return np.sum(pred_flat == labels_flat) / len(labels_flat)\n",
    "\n",
    "# 모델을 훈련시키는 함수입니다.\n",
    "def train(model, optimizer, dataloader):\n",
    "    model.train() # 모델을 훈련 모드로 설정합니다.\n",
    "    train_loss = 0.0 # 훈련 손실을 초기화합니다.\n",
    "\n",
    "    # 데이터로더로부터 배치 단위로 데이터를 가져옵니다.\n",
    "    for input_ids, attention_mask, labels in tqdm(dataloader, desc=\"Training\"):\n",
    "        # 모델에 데이터를 입력하여 출력(outputs)을 얻습니다.\n",
    "        outputs = model(input_ids=input_ids, attention_mask=attention_mask, labels=labels)\n",
    "        loss = outputs.loss # 출력에서 손실(loss) 값을 추출합니다.\n",
    "        train_loss += loss.item() # 손실 값을 누적합니다.\n",
    "\n",
    "        optimizer.zero_grad() # 옵티마이저의 기울기를 초기화합니다.\n",
    "        loss.backward() # 손실에 대한 역전파를 수행하여 기울기를 계산합니다.\n",
    "        optimizer.step() # 옵티마이저를 사용하여 모델 파라미터를 업데이트합니다.\n",
    "\n",
    "    train_loss = train_loss / len(dataloader) # 배치당 평균 손실을 계산합니다.\n",
    "    return train_loss # 평균 훈련 손실을 반환합니다.\n",
    "\n",
    "# 모델을 평가하는 함수입니다.\n",
    "def evaluation(model, dataloader):\n",
    "    with torch.no_grad(): # 기울기 계산을 비활성화하여 메모리를 절약하고 연산 속도를 높입니다.\n",
    "        model.eval() # 모델을 평가 모드로 설정합니다.\n",
    "        criterion = nn.CrossEntropyLoss() # 손실 함수로 교차 엔트로피 손실을 사용합니다.\n",
    "        val_loss, val_accuracy = 0.0, 0.0 # 검증 손실과 정확도를 초기화합니다.\n",
    "\n",
    "        # 데이터로더로부터 배치 단위로 데이터를 가져옵니다.\n",
    "        for input_ids, attention_mask, labels in tqdm(dataloader, desc=\"Evaluation\"):\n",
    "            outputs = model(input_ids=input_ids, attention_mask=attention_mask, labels=labels) # 모델에 데이터를 입력합니다.\n",
    "            logits = outputs.logits # 출력에서 로짓(logits) 값을 추출합니다.\n",
    "\n",
    "            loss = criterion(logits, labels) # 교차 엔트로피 손실을 계산합니다.\n",
    "            logits = logits.detach().cpu().numpy() # 로짓을 CPU로 이동 후 넘파이 배열로 변환합니다.\n",
    "            label_ids = labels.to(\"cpu\").numpy() # 라벨을 CPU로 이동 후 넘파이 배열로 변환합니다.\n",
    "            accuracy = calc_accuracy(logits, label_ids) # 정확도를 계산합니다.\n",
    "\n",
    "            val_loss += loss.item() # 손실 값을 누적합니다.\n",
    "            val_accuracy += accuracy # 정확도를 누적합니다.\n",
    "\n",
    "    val_loss = val_loss/len(dataloader) # 배치당 평균 손실을 계산합니다.\n",
    "    val_accuracy = val_accuracy/len(dataloader) # 배치당 평균 정확도를 계산합니다.\n",
    "    return val_loss, val_accuracy # 평균 손실과 정확도를 반환합니다.\n",
    "\n",
    "\n",
    "\n",
    "# 훈련 루프를 시작합니다.\n",
    "best_loss = 10000 # 최저 손실을 저장하기 위한 변수를 큰 값으로 초기화합니다.\n",
    "for epoch in range(epochs): # 지정된 에포크(epochs) 수만큼 반복합니다.\n",
    "    print(f\"--- Epoch {epoch + 1}/{epochs} ---\") # 에포크 진행 상황을 시각적으로 표시\n",
    "    train_loss = train(model, optimizer, train_dataloader) # 훈련 함수를 호출합니다.\n",
    "    val_loss, val_accuracy = evaluation(model, valid_dataloader) # 평가 함수를 호출합니다.\n",
    "    # 에포크별 훈련 손실, 검증 손실, 검증 정확도를 출력합니다.\n",
    "    print(f\"Epoch {epoch + 1}: Train Loss: {train_loss:.4f} Val Loss: {val_loss:.4f} Val Accuracy {val_accuracy:.4f}\")\n",
    "\n",
    "    # 현재 검증 손실이 기존의 최저 손실보다 낮으면 모델을 저장합니다.\n",
    "    if val_loss < best_loss:\n",
    "        best_loss = val_loss # 최저 손실을 업데이트합니다.\n",
    "        torch.save(model.state_dict(), \"../models/BertForSequenceClassification.pt\") # 모델의 가중치를 저장합니다.\n",
    "        print(\"Saved the model weights\") # 모델이 저장되었음을 알립니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "w56kZa0-r3Ks"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-multilingual-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "23409cd0814f48f0b1987b99278fbda2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluation:   0%|          | 0/125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss : 0.4030\n",
      "Test Accuracy : 0.8193\n"
     ]
    }
   ],
   "source": [
    "# 저장된 모델 가중치를 불러와 테스트 데이터셋으로 성능 평가\n",
    "# BertForSequenceClassification 모델을 불러옵니다.\n",
    "model = BertForSequenceClassification.from_pretrained(\n",
    "    pretrained_model_name_or_path=\"bert-base-multilingual-cased\", # 다국어 BERT 모델을 사용합니다.\n",
    "    num_labels=2).to(device) # 분류할 라벨의 개수를 2개로 설정하고, 모델을 지정된 device로 이동시킵니다.\n",
    "    # .to(device)는 모델을 GPU와 같은 가속기로 보내 연산을 빠르게 합니다.\n",
    "\n",
    "# 저장된 모델의 가중치(state_dict)를 불러와 현재 모델에 적용합니다.\n",
    "# torch.load() 함수를 이용해 파일 경로에 있는 가중치 파일을 불러옵니다.\n",
    "# model.load_state_dict() 메서드를 사용하여 불러온 가중치를 모델에 로드합니다.\n",
    "model.load_state_dict(torch.load(\"../models/BertForSequenceClassification.pt\"))\n",
    "\n",
    "# evaluation 함수를 사용하여 모델의 테스트 손실과 정확도를 계산합니다.\n",
    "test_loss, test_accuracy = evaluation(model, test_dataloader)\n",
    "\n",
    "# 계산된 테스트 손실과 테스트 정확도를 출력합니다.\n",
    "print(f\"Test Loss : {test_loss:.4f}\")\n",
    "print(f\"Test Accuracy : {test_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "v8KmMaCor44-"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WEONlYSEr4xq"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nefjNQl_r4me"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyOaJDtXDS0jFVdpyXCuk/U7",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "14f1b67d9e8843e2a0bdce02aa5ef22f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "217a2c5e01f1492d807e36bf3a433430": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "4b7025d4582b4a16937086360446cba1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a758c6a577ff42998ff1be3ddfa1d0e2",
      "placeholder": "​",
      "style": "IPY_MODEL_217a2c5e01f1492d807e36bf3a433430",
      "value": " 0/375 [00:00&lt;?, ?it/s]"
     }
    },
    "4f00601b2c97405388761fbb58e24d1c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_b162cfed23de47b9b27ba28f09e04bda",
      "placeholder": "​",
      "style": "IPY_MODEL_f8dc43ed87cd49b09b0f59347352f757",
      "value": "Training:   0%"
     }
    },
    "8321b303f8e0414c8c81c8c50e6d7928": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_cf74795110b54723b63cf784846c3e66",
      "max": 375,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_14f1b67d9e8843e2a0bdce02aa5ef22f",
      "value": 0
     }
    },
    "a758c6a577ff42998ff1be3ddfa1d0e2": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ad98cd2b440a49e6946e8ad6ef32f63e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b162cfed23de47b9b27ba28f09e04bda": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c95ec3d4a3bd4d51923251edea4db052": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_4f00601b2c97405388761fbb58e24d1c",
       "IPY_MODEL_8321b303f8e0414c8c81c8c50e6d7928",
       "IPY_MODEL_4b7025d4582b4a16937086360446cba1"
      ],
      "layout": "IPY_MODEL_ad98cd2b440a49e6946e8ad6ef32f63e"
     }
    },
    "cf74795110b54723b63cf784846c3e66": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f8dc43ed87cd49b09b0f59347352f757": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
